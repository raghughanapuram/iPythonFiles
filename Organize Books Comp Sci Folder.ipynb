{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning | Statistical Learning | Artificial Intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **The LION Way - Machine Learning *plus* Intelligent Optimization**\n",
    "    1. Introduction\n",
    "        - Lazy learning: nearest neighbors\n",
    "        - Learning requires a method\n",
    "    2. Supervised learning\n",
    "        - Linear models\n",
    "        - mastering generalized linear least-squares\n",
    "        - Rules, decision trees, and forests\n",
    "        - ranking and selecting features\n",
    "        - specific nonlinear models\n",
    "        - neural networks, shallow and deep\n",
    "        - statistical learning theory and support vector machines (SVM)\n",
    "        - democracy in machine learning\n",
    "    3. Unsupervised learning and clustering\n",
    "        - top-down clustering: K-means\n",
    "        - bottom-up (agglomerative) clustering\n",
    "        - self-organizing maps\n",
    "        - dimensionality reduction by linear transformations (projections)\n",
    "        - visualizing graphs and networks by nonlinear maps\n",
    "        - semi-supervised learning\n",
    "    4. Optimization: the source of power\n",
    "        - automated improvements by local steps\n",
    "        - local search and reactive search optimization (RSO)\n",
    "        - continuous and cooperative reactive search optimization (CoRSO)\n",
    "        - Multi-Objective Reactive Search Optimization (MORSO)\n",
    "    5. Selected Applications\n",
    "        - Text and web mining\n",
    "        - Collaborative filtering and recommendation\n",
    "- **Soft Computing - Techniques and its Applications in Electrical Engineering**\n",
    "    1. Introduction to Soft Computing\n",
    "        - fuzzy logic\n",
    "        - artificial neural networks\n",
    "        - introduction to evolutionary algorithms\n",
    "        - hybrid intelligent systems\n",
    "    2. Life History of Brain\n",
    "    3. Artificial Neural Network and Supervised Learning\n",
    "        - comparison of neural techniques and artifical intelligence\n",
    "        - artificial neuron structure\n",
    "        - adaline\n",
    "        - ANN learning\n",
    "        - back-propagation learning\n",
    "        - properties of neural networks\n",
    "        - limitations in the use of neural networks\n",
    "    4. Factors Affecting the Performance of Aritifical Neural Network Models\n",
    "        - network complexity\n",
    "            - neuron complexity\n",
    "            - number of layers\n",
    "            - number of neurons in each layer\n",
    "            - type and number of interconnecting weights\n",
    "        - problem complexity\n",
    "            - range of normalization of training data\n",
    "            - type of functional mapping\n",
    "            - sequence of presentation of training data\n",
    "            - repetition of data in the training set\n",
    "            - permissible noise in data\n",
    "        - learning complexity\n",
    "            - training algorithms of ANN\n",
    "            - selection of error functions\n",
    "            - mode of error calculation\n",
    "    5. Development of Generalized Neuron and its validation\n",
    "        - existing neuron model\n",
    "        - development of a generalized neuron (GN) model\n",
    "        - advantages of GN\n",
    "        - learning algorithms of a summation type generalized neuron\n",
    "        - benchmark testing of generalized neuron model\n",
    "    6. Applications of Generalized Neuron Models\n",
    "    7. Introduction to Fuzzy Set Theoretic Approach\n",
    "        - uncertainty and information\n",
    "        - types of uncertainty\n",
    "        - introduction of fuzzy logic\n",
    "        - historical development of fuzzy logic\n",
    "        - difference between precision and significance\n",
    "        - fuzzy set\n",
    "        - operations of fuzzy sets\n",
    "        - characteristics of fuzzy sets\n",
    "        - properties of fuzzy sets\n",
    "        - fuzzy cartesian product\n",
    "        - various shapes of fuzzy membership functions\n",
    "        - methods of defining of membership functions\n",
    "        - fuzzy compositional operators\n",
    "    8. Applications of Fuzzy Rule Based System\n",
    "    9. Genetic Algorithms\n",
    "        - history of genetics\n",
    "        - selection\n",
    "        - crossover\n",
    "        - mutation\n",
    "        - survival of fittest\n",
    "        - population size\n",
    "        - evaluation of fitness function\n",
    "        - effect of crossover probability on GA performance\n",
    "        - effect of mutation probability on GA performance\n",
    "    10. Applications of Genetic Algorithms to Load FOrecasting Problem\n",
    "    11. Synergism of Genetic Algorithms and Fuzzy Systems for Power System Applications\n",
    "    12. Integration of Neural Networks and Fuzzy Systems\n",
    "    13. ANN - GA-Fuzzy Synergism and its Applications\n",
    "- ** Machine Learning for Computer Vision**\n",
    "    1. **Throwing down the visual intelligence gauntlet**\n",
    "        - artificial intelligence: are we there yet?\n",
    "            - a compass for the uncharted journy toward intelligence\n",
    "        - the neuromorphic approach to visual intelligence\n",
    "            - anatomy and physiology of the primary visual cortex (V1)\n",
    "            - Hubel-Wiesel Models: Successive Tuning and Pooling\n",
    "            - Consistency with Experimental results and Multiple levels\n",
    "            - From neuroscience models to engineering applications\n",
    "        - what's next in the quest for visual intelligence?\n",
    "            - going beyond \"what is where\"\n",
    "            - from perception to abstraction\n",
    "            - a loost hierarchy of visual tasks\n",
    "            - it's time to try again - the MIT Intelligence initiative\n",
    "    2. actionable information in vision\n",
    "        - Preliminaries\n",
    "            - notation and conventions\n",
    "            - visibility and quantization\n",
    "            - invariant and sufficient statistics\n",
    "        - Placing the Ecological approach to visual perception onto computational grounds\n",
    "            - actionable information\n",
    "            - invertible and non-invertible nuisances\n",
    "            - the actionable information gap\n",
    "            - information pickup\n",
    "        - representational structures\n",
    "            - computing actionable information\n",
    "            - computing actionable information gap\n",
    "        - empirical consequences of the definitions\n",
    "            - exploration via information pickup\n",
    "    3. learning binary hash codes for large-scale image search\n",
    "        - search algorithms for binary codes\n",
    "        - supervised methods for learning binary projections\n",
    "        - unsupervised methods for defining binary projections\n",
    "    4. Bayesian painting by number: flexible priors of colour-invariant object recognition\n",
    "        - the colour-invariant admixture models\n",
    "        - using stels for supervised learning tasks\n",
    "    5. real-time human pose recognition in parts from single depth images\n",
    "    6. scale-invariant vote-based 3D recognition and registration from point clouds\n",
    "    7. Multiple classifier boosting and tree-structured classifiers\n",
    "    8. Simultaneous detection and tracking with multiple cameras\n",
    "    9. Applications of computer vision to vehicles: an extreme test\n",
    "- **Data Fusion for sensory information processing systems**\n",
    "    1. Introduction: he role of data fusion in sensory systems\n",
    "        - information acquisition: inverting the world-image mapping\n",
    "        - the need for constraints\n",
    "        - determination and embedding of constraints\n",
    "        - the need for data fusion\n",
    "    2. Bayesian Sensory Information Processing\n",
    "        - bayes rule\n",
    "        - the image formation model\n",
    "        - the priors\n",
    "        - bayesian estimators for $\\vec{f}$\n",
    "        - bayesian detection and extraction systems\n",
    "        - the bayesian controversy\n",
    "    3. Information processing using energy function minimization\n",
    "        - markov random fields\n",
    "        - energy functions with matching elements\n",
    "        - statistical mechanics and mean field theory\n",
    "        - the form of the smoothness constraint\n",
    "        - alternative forms of constraint\n",
    "    4. weakly vs. strongly coupled data fusion: a classification of fusional methods\n",
    "        - a classification of fusional methods\n",
    "        - weakly coupled data fusion\n",
    "        - strongly coupled data fusion algorithms\n",
    "        - bayesian implementation of data fusion\n",
    "        - examples of weakly coupled fusion in the vision literature\n",
    "        - examples of strongly coupled fusion in the vision literature\n",
    "    5. data fusion applied to feature based stereo algorithms\n",
    "        - the bayesian approach to stereo vision\n",
    "        - statistical mechanics and mean field theory\n",
    "        - comparison with other theories\n",
    "        - comparisons with psychophysical data\n",
    "    6. Fusing Binocular and monocular deppth cues\n",
    "        - strong fusion - stereo with monocular cues\n",
    "        - previous attempts at strong coupling for stereo\n",
    "    7. data fusion in shape from shading algorithms\n",
    "        - an algebraic approach to fusing specular and lambertian reflectance data\n",
    "        - a class III weakly coupled fusion implementation\n",
    "        - a strongly coupled approach to polychromatic shape from shading\n",
    "        - fusion of image formation models\n",
    "    8. temporal aspects of data fusion\n",
    "        - temporal coherence edge detector\n",
    "        - a strongly coupled temporal coherence edge detector\n",
    "        - temporal sampling\n",
    "        - active determination of constraints\n",
    "    9. Towards a constraint based theory of sensory data fusion\n",
    "- ** Handbook of Geometric Computing**\n",
    "    1. Neuroscience\n",
    "        - spatiotemporal dynamics of visual perception across neural maps and pathways\n",
    "        - symmetry, features and information\n",
    "    2. Neural Networks\n",
    "        - geometric approach to multilayer perceptrons\n",
    "        - a lattice algebraic approach to neural computation\n",
    "        - eigenproblems in pattern recognition\n",
    "    3. Image Processing\n",
    "        - geometric framework for image processing\n",
    "        - geometric filters, diffusion flows, and kernels in image processing\n",
    "        - chaos-based image encryption\n",
    "    4. Computer Vision\n",
    "        - one-dimensional retinae vision\n",
    "        - three-dimensional geometric computer vision\n",
    "        - Dynamic $\\mathcal{P}^n$ to $\\mathcal{P}^n$ Alignment\n",
    "        - detecting independent 3D movement\n",
    "    5. Perception and Action\n",
    "        - robot perception and action using conformal geometric algebra\n",
    "    6. Uncertainty in Geometric Computations\n",
    "        - uncertainty modeling and geometric inference\n",
    "        - uncertainty and projective geometry\n",
    "        - the tensor voting framework\n",
    "    7. Computer Graphcis and Visualization\n",
    "        - methods for nonrigid image registration\n",
    "        - the design of implicit functions for computer graphics\n",
    "    8. Geometry and Robotics\n",
    "        - grassmann-cayley algebra and robotics applications\n",
    "        - clifford algebra and robot dynamics\n",
    "        - geometric methods for multirobot optimal motion planning\n",
    "    9. Reaching and Motion Planning\n",
    "        - the computation of reachable surfaces for a specified set of spatial displacements\n",
    "        - planning collision-free paths using probabilistic roadmaps\n",
    "- **Neural Networks and Statistical Learning**\n",
    "    1. Introduction\n",
    "    2. Fundamentals of Machine Learning\n",
    "        - learning methods\n",
    "        - learning and generalization\n",
    "            - generalization error\n",
    "            - generalization by stopping criterion\n",
    "            - generalization by regularization\n",
    "            - fault tolerance and generalization\n",
    "            - sparsity versus stability\n",
    "        - model selection\n",
    "        - bias and variance\n",
    "        - robust leanring\n",
    "        - neural network processors\n",
    "        - criterion functions\n",
    "        - computational learning theory\n",
    "            - vapnik-chervonenkis dimension\n",
    "            - empirical risk-minimization principle\n",
    "            - probably approximately correct  learning\n",
    "        - no-free-lunch theorem\n",
    "        - neural networks as universal machines\n",
    "            - boolean function approximation\n",
    "            - linear separability and nonlinear separability\n",
    "            - continuous function approximation\n",
    "            - winner-takes-all\n",
    "        - compressed sensing and sparse approximation\n",
    "    3. Perceptrons\n",
    "        - one layer perceptron\n",
    "        - single-layer perceptron\n",
    "        - perceptron learning algorithm\n",
    "        - least-mean squares (LMS) algorithm\n",
    "        - P-delta rule\n",
    "    4. Multilayer Perceptrons: Architecture and Error Backpropagation\n",
    "        - universal approximation \n",
    "        - backpropagation learning algorithm\n",
    "        - incremental learning versus batch learning\n",
    "        - activation functions for the output layer\n",
    "        - optimizing network structure\n",
    "            - network pruning using sensitivty analysis\n",
    "            - network pruning using regularization\n",
    "            - network growing\n",
    "        - speeding up learning process\n",
    "            - eliminating premature saturation\n",
    "            - adapting learning parameters\n",
    "            - initializing weights\n",
    "            - adapting activation function\n",
    "        - some improved back propagation algorithms\n",
    "            - BP with global descent\n",
    "            - robust BP algorithms\n",
    "        - reslient propagation (RProp)\n",
    "    5. Mulilayer Perceptrons: other learning techniques\n",
    "        - introduction to second-order learning methods\n",
    "        - Newton's methods\n",
    "            - gauss-newton method\n",
    "            - levenberg-Marquardt method\n",
    "        - quasi-newton methods\n",
    "            - BFGS method\n",
    "            - one-step secant method\n",
    "        - conjugate-gradient methods\n",
    "        - extended kalman filtering methods\n",
    "        - recursive least squares\n",
    "        - natural-gradient descent method\n",
    "        - escaping local minima\n",
    "        - complex-valued MLPs and their learning\n",
    "    6. Hopfield networks, simulated annealing and chaotic neural networks\n",
    "        - hopfield model\n",
    "        - continuous-time hopfield network\n",
    "        - simulated annealing\n",
    "        - hopfield networks for optimization\n",
    "            - combinatorial optimization problems\n",
    "            - escaping local minimia for combinatorial optimization problems\n",
    "        - chaos and chaotic neural networks\n",
    "            - chaos, bifurcation, and fractals\n",
    "            - chaotic neural networks\n",
    "        - multistate hopfield networks\n",
    "        - cellular neural networks\n",
    "    7. associative memory networks\n",
    "        - hopfield model: storage and retrieval\n",
    "            - generalized hebbian rule\n",
    "            - pseudoinverse rule\n",
    "            - perceptron-type learning rule\n",
    "            - retrieval stage\n",
    "        - storage capability of the hopfield model\n",
    "        - increasing storage capacity\n",
    "        - multistate hopfield networks for associative memory\n",
    "        - multilayer perceptrons as associative memories\n",
    "        - hamming network\n",
    "        - bidirectional associative memories\n",
    "        - cohen-grossberg model\n",
    "        - cellular networks\n",
    "    8. Clustering I: Basic Clustering models and algorithms\n",
    "        - introduction\n",
    "            - vector quantization\n",
    "            - competitive learning\n",
    "        - self-organizing maps\n",
    "            - kohonen network\n",
    "            - basic self-organizing maps\n",
    "        - learning vector quantization\n",
    "        - nearest neighbor algorithms\n",
    "        - neural gas\n",
    "        - ART networks\n",
    "        - C-means clustering\n",
    "        - subtractive clustering\n",
    "        - fuzzy clustering\n",
    "    9. Clustering II: Topics in Clustering\n",
    "        - the underutilization problem\n",
    "            - competitive learning with conscience\n",
    "            - rival penalized competitive learning\n",
    "            - softcompetitive learning\n",
    "        - robust clustering\n",
    "            - possibilistic C-means\n",
    "            - a unified framework for robust clustering\n",
    "        - supervised clustering\n",
    "        - clustering using non-euclidean distance measures\n",
    "        - partitional, hierarchical, and density-based clustering\n",
    "        - hierarchical clustering\n",
    "        - constructive clustering techniques\n",
    "        - cluster validity\n",
    "        - projected clustering\n",
    "        - spectral clustering\n",
    "        - Coclustering\n",
    "        - Handling Qualitative data\n",
    "    10. Radial Basis Function Networks\n",
    "        - radial basis functions\n",
    "        - learning rbf centers\n",
    "        - learning the weights\n",
    "        - RBF network learning using orthogonal least-squares\n",
    "        - supervised learning of all parameters\n",
    "        - various learning methods\n",
    "        - normalized RBF networks\n",
    "        - optimizing network structure\n",
    "        - complex RBF networks\n",
    "        - comparison of RBF networks and MLPs\n",
    "    11. Recurrent Neural Networks\n",
    "        - fully connected recurrent networks\n",
    "        - time-delay neural networks\n",
    "        - backpropagation for temporal learning\n",
    "        - RBF networks for modeling dynamic systems\n",
    "        - some recurrent models\n",
    "        - reservoir computing\n",
    "    12. Principal Component Analysis\n",
    "        - Introduction\n",
    "            - Hebbian learning rule\n",
    "            - Oja's Learning rule\n",
    "        - PCA: conception and model\n",
    "        - Hebbian Rule-Based PCA\n",
    "            - subspace learning algorithms\n",
    "            - generalized hebbian algorithm\n",
    "        - least mean squared error-based PCA\n",
    "        - anti-Hebbian RUle-Based PCA\n",
    "        - Nonlinear PCA\n",
    "        - Minor Component Analysis\n",
    "        - Constrained PCA\n",
    "        - Localized PCA, incremental PCA, and supervised PCA\n",
    "        - complex-valued PCA\n",
    "        - two-dimensional PCA\n",
    "        - generalized eigenvalue decomposition\n",
    "        - singular value decomposition\n",
    "        - canonical corelation analysis\n",
    "    13. Nonnegative Matrix Factorization\n",
    "    14. Independent Component analysis\n",
    "    15. discriminant analysis\n",
    "    16. support vector machines\n",
    "        - SVM Model\n",
    "        - Solving the Quadratic Programming Problem\n",
    "            - chunking \n",
    "            - decomposition\n",
    "            - convergence of decomposition methods\n",
    "        - least-sqaures SVMs\n",
    "        - SVM training methods\n",
    "        - pruning SVMs\n",
    "        - multiclass SVMs\n",
    "        - support vector regression\n",
    "        - Support vector clusering\n",
    "        - distributed and parallel SVMS\n",
    "        - SVMs for active, trasductive and semi-supervised learning\n",
    "        - probabilistic approach to SVM\n",
    "    17. other kernel methods\n",
    "        - kernel PCA\n",
    "        - kernel LDA\n",
    "        - kernel clustering\n",
    "        - kernel autoassociators, kernel CCA and Kernel ICA\n",
    "    18. reinforcement learning\n",
    "        - learning through awards\n",
    "        - actor-critic model\n",
    "        - model-free and model-based reinforcement learning\n",
    "        - temporal-differnece learning\n",
    "        - Q-learning\n",
    "        - learning automata\n",
    "    19. probabilistic and bayesian networks\n",
    "        - bayesian network model\n",
    "        - learning bayesian networks\n",
    "            - learning the structure\n",
    "            - learning the parameters\n",
    "            - constraint-handling\n",
    "        - bayesian network inference\n",
    "            - belief popagation\n",
    "            - factor graphs and the belief propagation algorithm\n",
    "        - sampling (monte carlo) methods\n",
    "            - gibbs sampling\n",
    "        - variational bayesian methods\n",
    "        - hidden markov models\n",
    "        - dynamic bayesian networks\n",
    "        - expectation-maximization algorithm\n",
    "        - mixture models\n",
    "        - bayesian approach to neural network learning\n",
    "        - boltzmann machines\n",
    "            - boltzmann learning algorithm\n",
    "            - mean-field-theory machine\n",
    "            - stochastic hopfield networks\n",
    "        - training deep networks\n",
    "    20. combining multiple learners: data fusion and ensemble learning\n",
    "        - boosting\n",
    "        - bagging\n",
    "        - random forests\n",
    "        - topics in ensemble learning\n",
    "        - solving multiclass classification\n",
    "        - dempster-shafer theory of evidence\n",
    "    21. introduction to fuzzy sets and logic\n",
    "    22. neurofuzzy systems\n",
    "        - rule extraction from trained neural networks\n",
    "        - extracting rules from numerical data\n",
    "        - synergy of fuzzy logic and neural networks\n",
    "    23. Neural circuits and parallel implementation\n",
    "    24. pattern recognition for biometrics and bioinformatics\n",
    "    25. data mining\n",
    "- **Pattern Classification**\n",
    "    1. Introduction\n",
    "        - Macine perception\n",
    "        - pattern recognition systems\n",
    "            - sensing \n",
    "            - segmentation and grouping\n",
    "            - feature extraciton\n",
    "            - classification\n",
    "            - post processing\n",
    "        - the design cycle\n",
    "            - data collection\n",
    "            - feature choice\n",
    "            - model choice\n",
    "            - training\n",
    "            - evaluation\n",
    "            - computational complexity\n",
    "        - learning and adaptation\n",
    "            - supervised learning\n",
    "            - unsupervised learning\n",
    "            - reinforcement learning\n",
    "    2. Bayesian Decision Theory\n",
    "        - Bayesian decision theory - continuous features\n",
    "            - two-category classificaiton\n",
    "        - minimum-error-rate classifcation\n",
    "            - minimax criterion\n",
    "            - neyman-pearson criterion\n",
    "        - classifiers, discriminant functions and decision surfaces\n",
    "            - the mutlicategory case\n",
    "            - the two-category case\n",
    "        - the normal density\n",
    "            - univariate density\n",
    "            - multivariate density\n",
    "        - discriminant functions for the normal density\n",
    "        - error probabilities and integrals\n",
    "        - error bounds for normal densities\n",
    "        - bayes decision theory - discrete features\n",
    "        - missing and noisy features\n",
    "        - bayesian belief networks\n",
    "        - compound bayesian decision theory and context\n",
    "    3. Maximum-Likelihood and Bayesian Parameter Estimation\n",
    "        - maximum-likelihood estimation\n",
    "        - bayesian estimation\n",
    "        - bayesian parameter estimation: Gaussian Case\n",
    "        - Bayesian parameter estimation: General theory\n",
    "        - sufficient statistics\n",
    "        - problems of dimensionality\n",
    "        - component analysis and discriminants\n",
    "        - expectation-maximiazation (EM)\n",
    "        - hidden markov models\n",
    "    4. Nonparametric techniques\n",
    "        - density estimation\n",
    "        - parzen windows\n",
    "        - $k_n$-Nearest-neighbor estimation\n",
    "        - the nearest neighbor rule\n",
    "        - metrics and nearest-neighbor classification\n",
    "        - fuzzy classification\n",
    "        - reduced coulomb energy networks\n",
    "        - approximations by series expansions\n",
    "    5. Linear Discriminant Functions\n",
    "        - linear discriminant functions and decision surfaces\n",
    "        - generalized linear discriminant functions\n",
    "        - the two-category linearly separable case\n",
    "        - minimizing the perceptron criterion functions\n",
    "        - relaxation procedures\n",
    "        - nonseparable behavior\n",
    "        - minimum squared-error procedures\n",
    "        - the ho-kashyap procedures\n",
    "        - linear programming algorithms\n",
    "        - support vector machines\n",
    "        - multicategory generalizations\n",
    "    6. Multilayer neural networks\n",
    "        - Feedforward operation and classification\n",
    "        - backpropagation algorithm\n",
    "        - error surfaces\n",
    "        - backpropagation as feature mapping\n",
    "        - backpropagation, bayes theory and probability \n",
    "        - related statistical techniques\n",
    "        - practical techniques for improving backpropagation\n",
    "            - activation function\n",
    "            - parameters for the sigmoid\n",
    "            - scaling input\n",
    "            - target values\n",
    "            - training with noise\n",
    "            - manufacturing data\n",
    "            - number of hidden units\n",
    "            - initializing weights\n",
    "            - learning rates\n",
    "            - momentum \n",
    "            - weight decay\n",
    "            - hints\n",
    "            - on-line, stochastic or batch training\n",
    "            - stopped training\n",
    "            - number of hidden layers\n",
    "            - criterion function\n",
    "        - second-order methods\n",
    "            - Hessian Matrix\n",
    "            - Newton's method\n",
    "            - Quickdrop\n",
    "            - conjugate gradient descent\n",
    "        - additional networks and training methods\n",
    "            - radial basis function networks (RBFs)\n",
    "            - special bases\n",
    "            - matched filters\n",
    "            - convolutional networks\n",
    "            - recurrent networks\n",
    "            - cascade-correlation\n",
    "        - regularization, complexity adjustment and pruning\n",
    "    7. Stochastic methods\n",
    "        - stochastic search\n",
    "            - simulated annealing\n",
    "            - the boltzmann factor\n",
    "            - determinisitc simulated annealing\n",
    "        - boltzmann learning\n",
    "            - stochastic boltzmann learning of visible states\n",
    "            - missing features and category constraints\n",
    "            - deterministics boltzmann learning\n",
    "            - initialization and setting parameters\n",
    "        - boltzmann networks and graphical models\n",
    "        - evolutionary methods\n",
    "            - genetic algorithms\n",
    "            - further heuristics\n",
    "            - why do they work?\n",
    "        - genetic programming\n",
    "    8. Nonmetric methods\n",
    "        - Decision trees\n",
    "        - CART\n",
    "        - Other tree methods\n",
    "        - Recognition with strings\n",
    "        - grammatical methods\n",
    "        - grammatical inference\n",
    "        - rule-based methods\n",
    "    9. Algorithm-Independent Machine Learning\n",
    "        - lack of inherent superiority of any classifier\n",
    "        - bias and variance\n",
    "        - resampling for estimating statistics\n",
    "        - resampling for classifier design\n",
    "        - estimating and comparing classifiers\n",
    "        - combining classifiers\n",
    "    10. Unsupervised Learning and Clustering\n",
    "        - mixture densities and identifiability\n",
    "        - maximum-likelihood esimated\n",
    "        - application to normal mixtures\n",
    "        - unsupervised bayesian learning\n",
    "        - data description and clustering\n",
    "        - criterion functions for clustering\n",
    "        - iterative optimization\n",
    "        - hierarchical clustering\n",
    "        - the problem of validity\n",
    "        - on-line clustering\n",
    "        - graph-theoretic methods\n",
    "        - component analysis\n",
    "        - low-dimensional representation and multidimensional scaling (MDS)\n",
    "    11. Mathematical Foundations\n",
    "        - Linear Algebra\n",
    "            - notation and preliminaries\n",
    "            - inner product\n",
    "            - outer product\n",
    "            - derivatives of matrices\n",
    "            - determinany and trace\n",
    "            - matrix inversion\n",
    "            - eigenvectors and eigenvalues\n",
    "         - Lagrance optimization\n",
    "         - Probability theory\n",
    "             - discrete random variables\n",
    "             - expected values\n",
    "             - pairs of discrete random variables\n",
    "             - statistical independence\n",
    "             - expected values of functions of two variables\n",
    "             - conditional probability\n",
    "             - the law of total probability and baye's rule\n",
    "             - vector random variables\n",
    "             - expectations, mean vectors and covariance matrices\n",
    "             - continuous random variables\n",
    "             - distributions of sums of independent random variables\n",
    "             - normal distribution\n",
    "           - Gaussian derivatives and integrals\n",
    "           - hypothesis testing\n",
    "           - information theory\n",
    "           - computational complexity\n",
    "- ** Computational intelligence - an introduction**\n",
    "    1. Introduction\n",
    "        - computational intelligence paradigms\n",
    "            - artificial neural networks\n",
    "            - evolutionary computation\n",
    "            - swarm intelligence\n",
    "            - artficial immune systems\n",
    "            - fuzzy systems\n",
    "    2. Artificial Neural Networks\n",
    "        - The Artificial Neuron\n",
    "            - calculating the net input signal \n",
    "            - activation functions\n",
    "            - artificial neuron geometry\n",
    "            - artificial neuron learning\n",
    "                - augmented vectors\n",
    "                - gradient descent learning rule\n",
    "                - widrow-hoff learning rule\n",
    "                - generalized delta learning rule\n",
    "                - error-correction learning rule\n",
    "        - Supervised Learning Neural Networks\n",
    "            - neural network types\n",
    "                - feedforward neural networks\n",
    "                - functional link neuronal networks\n",
    "                - product unit neural networks\n",
    "                - simple recurrent neural networks\n",
    "                - time-delay neural networks\n",
    "                - cascade networks\n",
    "            - supervised learning rule\n",
    "                - the supervised learning problem\n",
    "                - gradient descent optimization\n",
    "                - scaled conjugate gradient\n",
    "                - leapFrog optimization\n",
    "                - particle swarm optimization\n",
    "            - functioning of hidden units\n",
    "            - ensemble neural networks\n",
    "        - Unsupervised Learning Neural Networks\n",
    "            - Hebbian learning rule\n",
    "            - principal component learning rule\n",
    "            - learning vector quantizer-I\n",
    "            - self-organizing feature maps\n",
    "                - stochastic training rule\n",
    "                - batch map\n",
    "                - growing SOM\n",
    "                - improving convergence speed\n",
    "                - clustering and visualization\n",
    "        - Radial Basis Function Networks\n",
    "            - learning vector quantizer - II\n",
    "            - radial basis function neural networks\n",
    "                - radial basis function network architecture\n",
    "                - radial basis functions\n",
    "                - training algorithms\n",
    "                - radial basis function network variations\n",
    "        - Reinforcement Learning\n",
    "            - learning through awards\n",
    "            - model-free reinforcement learning model\n",
    "                - temporal difference learning\n",
    "                - Q-learning\n",
    "            - Neural networks and reinforcement learning\n",
    "                - RPROP\n",
    "                - Gradient descent reinforcement learning\n",
    "                - connectionist Q-learning\n",
    "        - Performance Issues (supervised Learning)\n",
    "            - performance measures\n",
    "                - accuracy\n",
    "                - complexity\n",
    "                - convergence\n",
    "            - analysis of performance\n",
    "            - performance factors\n",
    "                - data preparation\n",
    "                - weight initialization\n",
    "                - learning rate and momentum\n",
    "                - optimization method\n",
    "                - architecture selection\n",
    "                - adaptive activation unctions\n",
    "                - active learning\n",
    "    3. Evolutionary Computation\n",
    "        - introduction to evolutionary computation\n",
    "            - generic evolutionary algorithm\n",
    "            - representation - the chromosome\n",
    "            - initial population\n",
    "            - fitness function\n",
    "            - selection\n",
    "                - selective pressure\n",
    "                - random selection\n",
    "                - proportional selection\n",
    "                - tournament selection\n",
    "                - rank-based selection\n",
    "                - boltzmann selection\n",
    "            - reproduction operators\n",
    "            - stopping conditions\n",
    "            - evolutionary computation versus classical optimization\n",
    "        - Genetic algorithms\n",
    "            - canoncial genetic algorithm\n",
    "            - crossover\n",
    "            - mutation\n",
    "            - control parameters\n",
    "            - genetic algorithm variants\n",
    "                - generation gap methods\n",
    "                - messy genetic algortihms\n",
    "                - interactive evolution\n",
    "                - island genetic algorithms\n",
    "            - advanced topics\n",
    "                - niching genetic algorithms\n",
    "                - constraint handling\n",
    "                - multi-objective optimization\n",
    "                - dynamic environments\n",
    "        - Genetic Programming\n",
    "            - tree-based representation\n",
    "            - initial population\n",
    "            - fitness function\n",
    "            - crossover operators\n",
    "            - mutation operators\n",
    "            - building block genetic programming\n",
    "        - evolutionary computation versus classical optimization\n",
    "            - basic evolutionary programming\n",
    "            - evolutionary programming operators\n",
    "                - mutation operators\n",
    "                - selection operators\n",
    "            - strategy parameters\n",
    "                - static strategy parameters\n",
    "                - dynamic strategies \n",
    "                - self-adaptation\n",
    "             - evolutionary programming implementations\n",
    "                - classical evolutionary programming\n",
    "                - fast evolutionary programming\n",
    "                - exponential evolutionary programming\n",
    "                - accelerated evolutionary programming\n",
    "                - momentum evolutionary programming\n",
    "                - evolutionary programming with local search\n",
    "                - evolutionary programming with extinction \n",
    "                - hybrid with particle swarm optimization\n",
    "             - advanced topics\n",
    "                - constraint handling approaches\n",
    "                - multi-objective optimization and niching\n",
    "                - dynamic environments\n",
    "             - Applications\n",
    "                - finite-state machines\n",
    "                - function optimization\n",
    "                - training neural networks\n",
    "        - evolution strategies\n",
    "            - (1+1)-ES\n",
    "            - Generic evolution strategy algorithm\n",
    "            - strategy parameters and self-adaptation\n",
    "            - evolutionary strategy operators\n",
    "                - selection operators\n",
    "                - crossover operators\n",
    "                - mutation operators\n",
    "            - evolution strategy variants\n",
    "                - polar evolution strategies\n",
    "                - evolutiona strategies with directed variation\n",
    "                - incremental evolution strategies\n",
    "                - surrogate evolution strategy\n",
    "            - advanced topics\n",
    "                - constraint handling approaches\n",
    "                - multi-objective optimization\n",
    "                - dynamic and noisy environments\n",
    "                - niching\n",
    "        - differential evolution\n",
    "            - basic differetial evolution\n",
    "                - difference vectors\n",
    "                - mutation\n",
    "                - crossover\n",
    "                - selection\n",
    "                - general differential evolution algorithm\n",
    "                - control parameters\n",
    "                - geometrical illustration\n",
    "            - DE/x/y/z\n",
    "            - Variations to basic differential evolution\n",
    "                - hybrid differential evolution strategies\n",
    "                - population-based differential evolution\n",
    "                - self-adaptive differential evolution\n",
    "            - differential evolution for discrete-valued problems\n",
    "        - cultural algorithms\n",
    "            - culture and artificial culture\n",
    "            - basic cultural algorithm\n",
    "            - belief space\n",
    "            - fuzzy cultural algorithms\n",
    "        - coevolution\n",
    "            - coevolution types\n",
    "            - competitive coevolution\n",
    "                - competitive fitness\n",
    "                - generic competitive coevolutionary algorithm\n",
    "            - cooperative coevolution\n",
    "    4. Computational Swarm Intelligence\n",
    "        - particle swarm optimization\n",
    "            - global best PSO\n",
    "            - local best PSO\n",
    "            - velocity components\n",
    "            - architecture selection\n",
    "        - ant algorithms\n",
    "            - foraging behavior of ants\n",
    "            - stigmergy and artificial pheromone\n",
    "            - simple ant colony optimizaiton\n",
    "            - ant system\n",
    "            - ant colony sytems\n",
    "            - division of labor\n",
    "            - task allocation based on response thresholds\n",
    "            - adaptive task allocation and specialization\n",
    "    5. Artificial Immune Systems\n",
    "        - natural immune system\n",
    "        - Artificial immune models\n",
    "    6. Fuzzy systems\n",
    "        - fuzzy sets\n",
    "        - fuzzy logic and reasoning\n",
    "        - fuzzy controllers\n",
    "        - rought sets\n",
    "        \n",
    "- **The Elements of Statistical Learning**\n",
    "    1. Introduction\n",
    "    2. Overview of Supervised Learning\n",
    "        - variable types and terminology\n",
    "        - two simple approaches to prediction: least squares and nearest neighbors\n",
    "        - statistical decision theory \n",
    "        - local methods in high dimensions\n",
    "        - statistical models, supervised learning and function approximation \n",
    "        - structured regression models\n",
    "        - classes of restricted estimators\n",
    "        - model selection and the bias-variance tradeoff\n",
    "    3. Linear Methods of Regression\n",
    "        - linear regression models and least squares\n",
    "        - subset selection\n",
    "        - shrinkage methods\n",
    "        - methods using derived input directions\n",
    "    4. Linear Methods for Classification\n",
    "        - linear regression of an indicator matrix\n",
    "        - linear discriminant analysis\n",
    "        - logistic regression\n",
    "        - separating hyperplanes\n",
    "    5. Basis Expansions and Regularization\n",
    "        - piecewise polynomials and splines\n",
    "        - filtering and feature extraction\n",
    "        - smoothing splines\n",
    "        - automatic selection of the smoothing parameters\n",
    "        - nonparametric logistic regression\n",
    "        - multidimensional splines\n",
    "        - regularization and reproducing kernel hilbert spaces\n",
    "        - wavelet smoothing\n",
    "    6. Kernel Smoothing Methods\n",
    "        - one-dimensional kernel smoothers\n",
    "        - selecting the width of the kernel \n",
    "        - local regression in $\\mathbb{R}^p$\n",
    "        - structured local regression models in $\\mathbb{R}^p$\n",
    "        - local likelihood and other models\n",
    "        - kernel density estimation and classification\n",
    "        - radial basis functions and kernels\n",
    "        - mixture models for density estimation and classification\n",
    "    7. Model Assessment and Selection\n",
    "        - bias, variance and model complexity\n",
    "        - the bias-variance decomposition\n",
    "        - optimism of the training error rate\n",
    "        - estimates of in-sample prediction error\n",
    "        - the effective number of parameters\n",
    "        - the bayesian approach and BIC\n",
    "        - minimum description length\n",
    "        - Vapnik-Chervonenkis dimension\n",
    "        - cross-validation\n",
    "        - bootstrap methods\n",
    "    8. Model Inference and Averaging\n",
    "        - the bootstrap and maximum likelihood methods\n",
    "        - bayesian methods\n",
    "        - relationship between the bootstrap and bayesian inference\n",
    "        - the EM algorithm\n",
    "        - MCMC for sampling for the posterior\n",
    "        - Bagging\n",
    "        - Model averaging and stacking\n",
    "        - stochastic search: bumping\n",
    "    9. Additive Models, Trees, and Related Methods\n",
    "        - generalized additive models\n",
    "        - tree-based methods\n",
    "        - PRIM: bump hunting\n",
    "        - MARS: multivariate adaptive regression splines\n",
    "        - hierarchical mixture of experts\n",
    "        - missing data\n",
    "    10. Boosting and Additive Trees\n",
    "        - boosting methods\n",
    "        - boosting fits and additive movel\n",
    "        - forward stagewise additive modeling\n",
    "        - exponential loss and AdaBoost\n",
    "        - why exponential loss?\n",
    "        - loss functions and robustness\n",
    "        - \"Off-the-shelf\" procedures for data mining\n",
    "        - boosting trees\n",
    "        - numerical optimization via gradient boosting\n",
    "        - right-sized trees for boosting\n",
    "        - regularization\n",
    "        - interpretation\n",
    "    11. Neural Networks\n",
    "        - projection pursuit regression\n",
    "        - fitting neural networks\n",
    "        - some issues in training neural networks\n",
    "            - starting values\n",
    "            - overfitting\n",
    "            - scaling of the inputs\n",
    "            - number of hidden units and layers\n",
    "            - multiple minima\n",
    "    12. Support Vector Machines and Flexible Discriminants\n",
    "        - the support vector classifier\n",
    "        - support vector machines an kernels\n",
    "            - computing the SVM for classification\n",
    "            - the SVM as a penalization method\n",
    "            - function estimation and reproducing kernels\n",
    "            - SVMs and the curse of dimensionality\n",
    "            - a path algorithm for the SVM classifier\n",
    "            - support vector machines for regression\n",
    "            - regression and kernels\n",
    "        - Generalizing linear discriminant analysis\n",
    "        - flexible discriminant analysis\n",
    "        - penalized discriminant analysis\n",
    "        - mixture discriminant analysis\n",
    "    13. Prototype Methods and Nearest-Neighbors\n",
    "        - protype methods\n",
    "            - K-means clustering\n",
    "            - learning vector quantization\n",
    "            - gaussian mixtures\n",
    "        - k-Nearest-Neighbors classifiers\n",
    "        - adaptive nearest-neighbor methods\n",
    "    14. Unsupervised Learning\n",
    "        - association rules\n",
    "        - cluster analysis\n",
    "            - proximity matrices\n",
    "            - dissimilarities based on attributes\n",
    "            - object dissimilarity\n",
    "            - clustering algorithms\n",
    "            - combinatorial algorithms\n",
    "            - K-means\n",
    "            - gaussian mixtures as soft K-means clustering\n",
    "            - vector quantization\n",
    "            - k-medoids\n",
    "            - hierarchical clustering\n",
    "         - self-organizing maps\n",
    "         - principal components, curves and surfaces\n",
    "             - principal componenets\n",
    "             - principal curves and surfaces\n",
    "             - spectral clustering\n",
    "             - kernel principal components\n",
    "             - sparse principal components\n",
    "         - non-negative matrix factorization\n",
    "         - independent component analysis and exploratory projection pursuit\n",
    "         - multidimensional scaling\n",
    "         - nonlinear dimension reduction and local multidimensional scaling\n",
    "         - the Google PageRank Algorithm\n",
    "    15. Random Forests\n",
    "        - definition of random forests\n",
    "        - details of random forests\n",
    "            - out of bag samples\n",
    "            - variable importance\n",
    "            - proximity plots\n",
    "            - random forests and overfitting\n",
    "        - analysis of random forests\n",
    "            - variance and the de-correlation effect\n",
    "            - bias\n",
    "            - adaptive nearest neighbors\n",
    "    16. Ensemble Learning\n",
    "        - boosting and regularization paths\n",
    "            - penalized regression\n",
    "            - the \"bet on sparsity\" principle\n",
    "            - regularization paths, over-fitting and margins\n",
    "        - learning ensembles\n",
    "    17. Undirected Graphical Models\n",
    "        - markov graphs and their properties\n",
    "        - undirected graphical models for continuous variables\n",
    "        - undirected graphical models for discrete variables\n",
    "    18. High-dimensional problems: $p>>N$\n",
    "        - diagonal linear discriminant analysis and nearest shrunken centroids\n",
    "        - linear classifiers with quadratic regularization\n",
    "            - regularized discriminany analysis\n",
    "            - logistic regression with quadratic regularization\n",
    "            - the support vector classifier\n",
    "            - feature selection\n",
    "            - computational shortcuts when $p>>N$\n",
    "        - linear classifiers with $L_1$ regularization\n",
    "        - classification when features are unavailable\n",
    "        - high-dimensional regression: supervised pricipal components\n",
    "        - feature assessment and the multiple-testing problem\n",
    "- **Neural networks and learning machines** (need to expand TOC for good meaty details)\n",
    "    1. Introduction\n",
    "    2. Rosenblatt's Perceptron\n",
    "    3. Model Building through regression\n",
    "    4. The Least-Mean-Square Algorithm\n",
    "    5. Multilayer perceptrons\n",
    "    6. kernel methods and radial-basis function networks\n",
    "    7. support vector machines\n",
    "    8. regularization theory\n",
    "    9. principal-components analysis\n",
    "    10. self-organizing maps\n",
    "    11. information-theoretic learning models\n",
    "    12. stochastic methods rooted in statistical mechanics\n",
    "    13. dynamic programming\n",
    "    14. neurodynamics\n",
    "    15. Bayesian filtering for state estimation of dynamic systems\n",
    "    16. dynamically driven recurrent networks\n",
    "- **Computational Intelligence - A methodological introduction**\n",
    "    1. Neural networks\n",
    "        - motivation and biological background\n",
    "        - threshold logic units (geometric interpretation, limitations, training parameters)\n",
    "        - general neural networks (structure, operation, training)\n",
    "        - multi-layer perceptrons (back prop, gradient descent)\n",
    "        - radial basis function networks\n",
    "        - self-organizing maps\n",
    "        - hopfield networks\n",
    "        - recurrent networks (representing diff eqns, vectorial NNs, error BP in time)\n",
    "        - mathematical remarks\n",
    "    2. Evolutionary Algorithms\n",
    "        - introduction to evolutionary algorithms \n",
    "        - elements of evolutionary algorithms (fitness, selection ,genetic operators)\n",
    "        - fundamental evolutionary algorithms (GA, GP, evolutionary strategies)\n",
    "        - Special applications and techniques\n",
    "    3. Fuzzy systems\n",
    "        - fuzzy sets and fuzzy logic\n",
    "        - the extension principle\n",
    "        - fuzzy relations\n",
    "        - similarity relations\n",
    "        - fuzzy control\n",
    "        - fuzzy clustering\n",
    "    4. Bayes Networks\n",
    "        - introduction to bayes networks\n",
    "        - elements of probability and graph theory\n",
    "        - decompositions\n",
    "        - evidence propagation\n",
    "        - learning graphical models\n",
    "- **Foundations of Machine Learning**\n",
    "    1. The PAC learning framework\n",
    "    2. Rademacher Complexity and VC-dimension\n",
    "    3. Support vector machines\n",
    "    4. kernel methods\n",
    "    5. boosting\n",
    "    6. on-line learning\n",
    "    7. multi-class classification\n",
    "    8. ranking\n",
    "    9. regression\n",
    "    10. algorithmic stability\n",
    "    11. dimensionality reduction\n",
    "    12. learning automata and languages\n",
    "    13. reinforcement learning\n",
    "    14. a linear algebra review\n",
    "    15. convex optimization\n",
    "    16. probability review\n",
    "    17. concentration inequalities\n",
    "- **Computational statistics Handbook with MATLAB**\n",
    "    1. Probability concepts\n",
    "        - axioms of probability\n",
    "        - conditional probability\n",
    "        - independence\n",
    "        - expectation (mean, variance, skewness, kurtosis)\n",
    "        - common distributions\n",
    "    2. sampling concepts\n",
    "        - sample mean, sample variance, sample moments, covariance\n",
    "        - sampling distributions\n",
    "        - paramter estimation (bias, MSE, SE, MLE, methods of moments)\n",
    "        - empirical distribution function \n",
    "    3. generating random variables\n",
    "        - generating random variables\n",
    "        - generating continuous random variables\n",
    "        - generating discrete random variables\n",
    "    4. exploratory data analysis\n",
    "        - exploring univariate data\n",
    "        - exploring bivariate and trivariate data\n",
    "        - exploring multi-dimensional data\n",
    "    5. monte carlo methods for inferential statistics\n",
    "        - classical inferential statistics\n",
    "        - monte carlo methods for inferential statistics\n",
    "        - bootstrap methods\n",
    "    6. data partitioning\n",
    "        - cross-validation\n",
    "        - jackknife\n",
    "        - better bootstrap confidence intervals\n",
    "        - jackknife-after-bootstrap\n",
    "    7. probability density estimation\n",
    "        - histograms\n",
    "        - kernel density estimation\n",
    "        - finite mixtures\n",
    "        - generating random variables\n",
    "    8. statistical pattern recognition\n",
    "        - bayes decision theory\n",
    "        - evaluating the classifier\n",
    "        - classificaiton trees\n",
    "        - clustering\n",
    "    9. nonparametric regression\n",
    "        - smoothing\n",
    "        - kernel methods\n",
    "        - regression trees\n",
    "    10. markov chain monte carlo methods\n",
    "        - metropolis-hastings algorithms\n",
    "        - the Gibbs sampler\n",
    "        - convergence monitoring\n",
    "    11. spatial statistics\n",
    "        - visualizing spatial point processes\n",
    "        - exploring first-order and second-order properties\n",
    "        - modelin spatial point processes\n",
    "        - simulating spatial point processes\n",
    "- **Machine Learning - a probabilistic perspective**\n",
    "    1. Introduction\n",
    "        - machine learning: what and why?\n",
    "        - supervised learning (classification/regression)\n",
    "        - unsupervised learning (discovering clusters/latent factors/graph structure & matrix completion)\n",
    "        - some basic concepts in machine learning\n",
    "            - parametric v. non-parametric models\n",
    "            - simple non-parametric classifier: K-nearest neighbors\n",
    "            - the curse of dimensionality\n",
    "            - parametric models for classification and regression\n",
    "            - linear regression\n",
    "            - logistic regression\n",
    "            - overfitting\n",
    "            - model selection\n",
    "            - no free lunch theorem\n",
    "    2. Probability\n",
    "        - a brief review of probability theory\n",
    "        - some common discrete distributions\n",
    "        - some common continuous distributions\n",
    "        - joint probability distributions\n",
    "        - transformations of random variables\n",
    "        - monte carlo approximation\n",
    "        - information theory\n",
    "    3. Generative models for discrete data\n",
    "        - bayesian concept learning\n",
    "            - likelihood, prior, posterior, posterior predictive distribution\n",
    "        - the beta-binomial model\n",
    "        - the Dirichlet-multinomial model\n",
    "        - Naive Bayes classifiers\n",
    "    4. Gaussian models\n",
    "        - Gaussian discriminant analysis\n",
    "        - inference in jointly Gaussian distributions\n",
    "        - linear gaussian systems\n",
    "        - digression: the wishart distribution\n",
    "        - inferring the paramters of an MVN\n",
    "    5. Bayesian statisics\n",
    "        - summarizing posterior distributions\n",
    "        - bayesian model selections\n",
    "        - priors\n",
    "        - hierarchical Bayes\n",
    "        - Empirical Bayes\n",
    "        - Bayesian decision theory\n",
    "    6. Frequentist statistics\n",
    "        - sampling distribution of an estimator\n",
    "        - frequentist decision theory \n",
    "        - desirable properties of estimators\n",
    "        - empirical risk minimization \n",
    "        - pathologies of frequentist statistics\n",
    "    7. Linear regression\n",
    "        - model specification\n",
    "        - maximum likelihood estimation (least squares)\n",
    "        - robust linear regression\n",
    "        - ridge regression\n",
    "        - Bayesian linear regression\n",
    "    8. Logistic regression\n",
    "        - model specification\n",
    "        - model fitting\n",
    "        - Bayesian logistic regression\n",
    "        - Online learning and stochastic optimization\n",
    "        - generative vs discriminative classifiers\n",
    "    9. Generalized linear models and the exponential family\n",
    "        - the exponential family\n",
    "        - Generalized linear models (GLMs)\n",
    "        - Probit regression\n",
    "        - multi-task learning\n",
    "        - generalizated linear mixed models\n",
    "        - learning to rank\n",
    "    10. Directed graphical models (Bayes nets)\n",
    "        - inference\n",
    "        - learning\n",
    "        - conditional independence properties of DGMs\n",
    "        - influence (decision) diagrams\n",
    "    11. Mixture models and the EM algorithm\n",
    "        - latent variable models\n",
    "        - mixture models\n",
    "        - parameter estimation for mixture models\n",
    "        - the EM algorithm\n",
    "        - model selection for latent variable models\n",
    "        - fitting models with missing data\n",
    "    12. Latent linear models\n",
    "        - factor analysis\n",
    "        - principal component analysis (PCA)\n",
    "        - choosing the number of latent dimensions\n",
    "        - PCA for categorical data\n",
    "        - PCA for paired and multi-view data\n",
    "        - Independent component analysis (ICA)\n",
    "    13. Sparse linear models\n",
    "        - Bayesian variable selection\n",
    "        - $\\mathscr{l}_1$ regularization: basics\n",
    "        - $\\mathscr{l}_1$ regularization: algorithms\n",
    "        - $\\mathscr{l}_1$ regularization: extensions\n",
    "        - Non-convex regularizers\n",
    "        - Automatic relevance determination (ARD)/sparse Bayesian learning (SBL)\n",
    "        - Sparse coding\n",
    "    14. Kernels\n",
    "        - Kernel functions\n",
    "        - Using kernels inside GLMs\n",
    "        - The kernel trick\n",
    "        - Support vector machines (SVMs)\n",
    "        - Comparison of discriminative kernel methods\n",
    "        - Kernels for building generative models\n",
    "    15. Gaussian processes\n",
    "        - GPs for regression\n",
    "        - GPs meet GLMs\n",
    "        - Connection with other methods\n",
    "        - GP latent variable model\n",
    "        - Approximation methods for large datasets\n",
    "    16. Adaptive basis function models\n",
    "        - Classificaiton and regression trees (CART)\n",
    "        - Generalized additive models\n",
    "        - Boosting\n",
    "        - Feedforward neural networks (multilayer perceptrons)\n",
    "        - ensemble learning\n",
    "        - experimental comparison\n",
    "        - interpreting black-box models\n",
    "    17. Markov and hidden Markov models\n",
    "        - Markov models\n",
    "        - Hidden Markov models\n",
    "        - Inference in HMMs\n",
    "        - Learning for HMMs\n",
    "        - Generalizaitons of HMMs\n",
    "    18. State space models\n",
    "        - Applications of SSMs\n",
    "        - Inference in LG-SSM\n",
    "        - Learning for LG-SSM\n",
    "        - Approximate online inference for non-linear, non-Gaussian SSMs\n",
    "        - Hybrid discrete/continuous SSMs\n",
    "    19. Undirected graphical models (Markov random fields)\n",
    "        - conditional independence properties of UGMs\n",
    "        - parameterization of MRFs\n",
    "        - Examples of MRFs (ising, hopfield, potts, gaussian, markov logic)\n",
    "        - Learning\n",
    "        - Conditional random fields (CRFs)\n",
    "        - Structural SVMs\n",
    "    20. Exact inference for graphical models\n",
    "        - Belief propagation for trees\n",
    "        - the variable elimination algorithm\n",
    "        - the junction tree algorithm\n",
    "        - computational intractability of exact inference in the worst case\n",
    "    21. Variational inference\n",
    "        - variational inference\n",
    "        - the mean field method\n",
    "        - structured mean field\n",
    "        - variational Bayes\n",
    "        - variational Bayes EM\n",
    "        - variational message passing and VIBES\n",
    "        - local variational bounds\n",
    "    22. More variational inference\n",
    "        - loopy belief propagation: algorithmic issues\n",
    "        - loopy belief propagation: theoretical issues\n",
    "        - extensions of belief propagation\n",
    "        - expectation propagation\n",
    "        - MAP state estimation\n",
    "    23. Monte Carlo inference\n",
    "        - sampling from standard distributions\n",
    "        - rejection sampling\n",
    "        - importance sampling\n",
    "        - particle filtering\n",
    "        - Rao-Blackwellised particle filtering (RBPF)\n",
    "    24. Markov Chain Monte Carlo (MCMC) inference\n",
    "        - Gibbs sampling\n",
    "        - Metropolis Hastings algorithm\n",
    "        - Speed accuracy of MCMC\n",
    "        - Auxiliary variable MCMC\n",
    "        - Annealing methods\n",
    "        - approximating the marginal likelihood\n",
    "    25. Clustering\n",
    "        - Dirichlet process mixture models\n",
    "        - affinity propagation\n",
    "        - Spectral clustering\n",
    "        - hierarchical clustering\n",
    "        - clustering datapoints and features\n",
    "    26. Graphical model structure learning\n",
    "        - structure learning for knowledge discovery\n",
    "        - learning tree structures\n",
    "        - learning DAG structures\n",
    "        - learning DAG structures with latent variables\n",
    "        - Learning causal DAGs\n",
    "        - learning undirected Gaussian graphical models\n",
    "        - Learning undirected discrete graphical models\n",
    "    27. Latent variable models for discrete data\n",
    "        - distributed state LVMs for discrete data\n",
    "        - latent Dirichlet allocation (LDA)\n",
    "        - Extensions of LDA\n",
    "        - LVMs for graph-structured data\n",
    "        - LVMs for relational data\n",
    "        - Restricted Boltzmann machines (RBMs)\n",
    "    28. Deep learning\n",
    "        - deep generative models\n",
    "            - deep directed networks\n",
    "            - deep boltzmann machines\n",
    "            - deep belief networks\n",
    "            - greedy layer-wise learning of DBNs\n",
    "        - deep neural networks\n",
    "            - deep multi-layer perceptrons\n",
    "            - deep auto-encoders\n",
    "            - stacked denoising auto-encoders\n",
    "        - applications of deep networks\n",
    "- ** Bio-inspired Artificial Intelligence - theories, methods, and technologies**\n",
    "    1. Evolutionary systems\n",
    "        1. pillars of evolutionary theory\n",
    "        2. the genotype\n",
    "        3. artificial evolution\n",
    "        4. genetic representations\n",
    "        5. initial population\n",
    "        6. fitness functions\n",
    "        7. selection and reproduction\n",
    "        8. genetic operators\n",
    "        9. evolutionary measures\n",
    "        10. types of evolutionary algorithms\n",
    "        11. scheme theory\n",
    "        12. human-competitive evolution\n",
    "        13. evolutionary electronics\n",
    "        14. lessonfs from evolutionary electronics\n",
    "        15. the role of abstraction\n",
    "        16. analog and digital circuits\n",
    "        17. extrinsic and intrinsic evolution\n",
    "        18. digital design\n",
    "        19. evolutionary digital design\n",
    "        20. analog design\n",
    "        21. evolutionary analog design\n",
    "        22. multiple objectives and contraints\n",
    "        23. design verification\n",
    "    2. Cellular Systems\n",
    "        1. The Basic Ingredients\n",
    "        2. Cellular Automata\n",
    "        3. Modeling with cellular systems\n",
    "        4. some classic cellular automata\n",
    "        5. other cellular systems\n",
    "        6. computation\n",
    "        7. artificial life\n",
    "        8. complex systems\n",
    "        9. analysis and synthesis of cellular systems\n",
    "    3. Neural Systems\n",
    "        1. biological nervous systems\n",
    "        2. artificial neural networks\n",
    "        3. neuron models\n",
    "        3. architecture\n",
    "        4. signal encoding\n",
    "        5. synaptic plasticity\n",
    "        6. unsupervised learing\n",
    "        7. supervised learning\n",
    "        8. reinforcement learning\n",
    "        9. evolution of neural networks\n",
    "        10. neural hardware\n",
    "        11. hybrid neural systems\n",
    "    4. Developmental Systems\n",
    "        1. potential advantages of a developmental representation\n",
    "        2. rewriting systems\n",
    "        3. synthesis of developmental systems\n",
    "        4. evolution and development\n",
    "        5. defining artificial evolutionary developmental systems\n",
    "        6. evolutionary rewriting systems\n",
    "        7. evolutionary developmental programs\n",
    "        8. evolutionary developmental processes\n",
    "    5. Immune Systems\n",
    "        1. How biological immune systems work\n",
    "        2. the constituents of biological immune systems\n",
    "        3. lessons for artificial immune systems\n",
    "        4. algorithms\n",
    "        5. shape space\n",
    "        6. negative selection algorithm\n",
    "        7. clonal selection algorithm\n",
    "    6. Behavioral Systems\n",
    "        1. behavior in cognitive science\n",
    "        2. behavior in artificial intelligence\n",
    "        3. behavior-based robotics\n",
    "        4. biological inspiration for robots\n",
    "        5. robots as biological models\n",
    "        6. robot learning\n",
    "        7. evolution of behavioral systems\n",
    "        8. evolution and learning in behavioral systems\n",
    "        9. evolution and neural development in behavioral systems\n",
    "        10. coevolution of body and control\n",
    "        11. toward self-reproductions\n",
    "        12. simulation and reality\n",
    "    7. Collective Systems\n",
    "        1. biological self-organization\n",
    "        2. particle swarm optimization\n",
    "        3. ant colony optimization\n",
    "        4. swarm robotics\n",
    "        5. coevolutionary dynamics: biological models\n",
    "        6. artificial evolution of competing systems\n",
    "        7. artificial evolution of cooperation\n",
    "- **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "- **Learning with Kernels**\n",
    "    1. A tutorial introduction\n",
    "        - data representation and similarity\n",
    "        - a simple pattern recognition algorithm\n",
    "        - some insights from statistical learning theory\n",
    "        - hyperplane classifiers\n",
    "        - support vector classification\n",
    "        - support vector regression\n",
    "        - kernel principal component analysis\n",
    "    2. Concepts and Tools\n",
    "        1. Kernels\n",
    "            - product features\n",
    "            - the representation of similarities in linear spaces\n",
    "            - examples and properties of kernels\n",
    "            - the representation of dissimilarities in linear spaces\n",
    "        2. Risk and Loss Functions\n",
    "            - loss functions\n",
    "            - test error and expected risk\n",
    "            - a statistical perspective\n",
    "            - robust estimators\n",
    "        3. Regularization\n",
    "            - the regularized risk functional \n",
    "            - the representer theorem\n",
    "            - regularization operators\n",
    "            - translation invariant kernels\n",
    "            - translation invariant kernels in higher dimensions\n",
    "            - dot product kernels\n",
    "            - multi-output regularization\n",
    "            - semiparametric regularization\n",
    "            - coefficient based regularization\n",
    "        4. Elements of statistical Learning theory\n",
    "            - the law of large numbers\n",
    "            - when learning does work: the question of consistency\n",
    "            - uniform convergence and consistency\n",
    "            - how to derive a VC bound\n",
    "            - a model selection example\n",
    "        5. Optimization\n",
    "            - convex optimization\n",
    "            - unconstrained problems\n",
    "            - constrained problems\n",
    "            - interior point methods\n",
    "            - maximum search problems\n",
    "    3. Support Vector Machines\n",
    "        1. Pattern Recognition\n",
    "            - separating hyperplanes\n",
    "            - the role of the margin\n",
    "            - optimal margin hyperplanes\n",
    "            - nonlinear support vector classifiers\n",
    "            - soft margin hyperplanes\n",
    "            - multi-class classification\n",
    "        2. Single-Class Problems: Quantile Estimation and Novelty Detection\n",
    "        3. Regression Estimation\n",
    "            - linear regression with insensitive loss function\n",
    "            - dual problems\n",
    "            - $\\nu$-SV Regression\n",
    "            - Convex Combinations and $\\mathscr{l}_1$-Norms\n",
    "            - Parametric insensitivity models\n",
    "        4. Implementation\n",
    "            - tricks of the trade\n",
    "            - sparse greedy matrix approximation\n",
    "            - interior point algorithms\n",
    "            - subset selection methods\n",
    "            - sequential minimal optimization\n",
    "            - iterative methods\n",
    "        5. Incorporating Invariances\n",
    "            - prior knowledge\n",
    "            - transofmration invariance\n",
    "            - the virtual SV method\n",
    "            - constructing invariance kernels\n",
    "            - the jittered SV method\n",
    "        6. Learning theory revisited\n",
    "            - concentration of measure inequalities\n",
    "            - leave-one-out estimates\n",
    "            - PAC-Bayesian bounds\n",
    "            - operator-theoretic methods in learning theory\n",
    "    4. Kernel Methods\n",
    "        1. Designing Kernels\n",
    "            - tricks for constructing kernels\n",
    "            - string kernels\n",
    "            - locality-improved kernels\n",
    "            - natural kernels\n",
    "        2. Kernel Feature extraction\n",
    "        3. Kernel Fisher Discriminant\n",
    "        4. Bayesian Kernel Methods\n",
    "        5. Regularized Principal manifolds\n",
    "        6. pre-images and reduced set methods\n",
    "    5. Mathematical Prerequisites\n",
    "        1. Probability\n",
    "        2. Linear Algebra\n",
    "        3. Functional Analysis\n",
    "- **The Computer Revolution in Philosophy - Philosophy, Science and Models of Mind**\n",
    "    1. Introduction and Overview\n",
    "    2. Methodological Preliminaries\n",
    "        1. What are the aims of science?\n",
    "        2. Science and Philosophy\n",
    "        3. What is conceptual analysis?\n",
    "        4. Are computers really relevant?\n",
    "    3. Mechanisms\n",
    "        1. Sketch of an intelligent mechanism\n",
    "        2. Intuition and analogical reasoning\n",
    "        3. on learning about numbers: some problems and speculations\n",
    "        4. Perception as a computational process\n",
    "        5. Conclusion: AI and philosophical problems\n",
    "- **Optimization for Machine Learning**\n",
    "    1. Introduction: Optimization and Machine Learning\n",
    "    2. Convex Optimization with Sparsity-Inducing Norms\n",
    "    3. Interior-Point Methods for Large-Scale Cole Programming\n",
    "    4. Incremental Gradient, subgradient and proximal methods for convex optimization: a survey\n",
    "    5. First-order methods for nonsmooth convex Large-scale Optimization, I: General Purpose methods\n",
    "    6. First-order methods for nonsmooth convex Large-scale Optimization, II: Utilizing Problem's Structure\n",
    "    7. Cutting-Plane methods in Machine learning\n",
    "    8. Introduction to Dual decomposition for inference\n",
    "    9. Augmented Lagrangian methods for learning, selecting and combining features\n",
    "    10. the convex optimization approach to regret minimization\n",
    "    11. projected newton-type methods in machine learning\n",
    "    12. interior-point methods in machine learning\n",
    "    13. The tradeoff of large-scale learning\n",
    "    14. Robust optimization in machine learning\n",
    "    15. Improving First and second-order methods by modeling uncertainty\n",
    "    16. Bandit view on noisy optimization\n",
    "    17. Optimization methods for Sparse inverse covariance selection\n",
    "    18. a pathwise algorithm for covariance selection\n",
    "- **Computational Intelligence Paradigms for MATLAB**\n",
    "    1. Computational intelligence\n",
    "        - primary classes of problems for CI techniques\n",
    "            - optimization\n",
    "            - NP-complete problems\n",
    "        - feed forward neural networks\n",
    "        - fuzzy systems\n",
    "        - evolutionary computing\n",
    "            - genetic algorithms\n",
    "            - genetic programming\n",
    "            - evolution programming\n",
    "            - evolutionary strategies\n",
    "        - swarm intelligence\n",
    "        - other paradigms\n",
    "            - granular computing\n",
    "            - chaos theory\n",
    "            - artificial immune systems\n",
    "        - hybrid approaches\n",
    "    2. Artificial Neural Networks with MATLAB\n",
    "        - implementation\n",
    "        - operations\n",
    "        - training\n",
    "        - teaching\n",
    "        - learning rates\n",
    "        - learning laws\n",
    "    3. ANNs - Architectures and algorithms\n",
    "        - single-layer\n",
    "        - multi-layer\n",
    "        - perceptron\n",
    "        - feedforward back-propagation network\n",
    "        - delta bar delta network\n",
    "        - directed random search network\n",
    "    4. Classification and Association neural networks\n",
    "        - learning vector quantificaiton\n",
    "        - counter-propagation network\n",
    "        - probabilistic neural network\n",
    "        - data association networks\n",
    "            - hopfield network\n",
    "            - boltzmann machine\n",
    "            - hamming network\n",
    "            - bi-directional associative memory\n",
    "        - data conceptualization networks\n",
    "            - adaptive resonance network\n",
    "            - ART algorithm\n",
    "            - self-organizing map\n",
    "    5. Matlab programs to implement neural networks\n",
    "    6. MATLAB-based fuzzy systems\n",
    "    7. Fuzzy inference and expert systems\n",
    "    8. MATLAB illustration on fuzzy systems\n",
    "    9. Neuro-fuzzy modeling using MATLAB\n",
    "    10. Evolutionary Computation paradigms\n",
    "        - evolutionary algorithms parameters\n",
    "        - solution representation\n",
    "        - fitness function\n",
    "        - initialization of population size\n",
    "        - selection mechanisms\n",
    "        - crossover technique\n",
    "        - mutation operator\n",
    "        - reproduction operator\n",
    "        - evolutionary programming\n",
    "        - evolutionary strategies\n",
    "            - solution representation\n",
    "            - mutation\n",
    "            - recombination\n",
    "            - population assessment\n",
    "            - convergence criteria\n",
    "    11. Evolutionary algorithms implemented using MATLAB\n",
    "    12. MATLAB-based genetic algorithm\n",
    "        - encoding and optimization problems\n",
    "        - historical overview of genetic algorithm\n",
    "        - description\n",
    "        - solution representation of genetic algorithms\n",
    "        - parameters of GA\n",
    "        - schema theora and background\n",
    "        - crossover operators and schemata\n",
    "        - genotype and fitness\n",
    "        - advanced operators in GA\n",
    "            - inversion and reordering\n",
    "            - epistasis\n",
    "            - deception\n",
    "            - mutation and naive evolution\n",
    "            - niche and speciation \n",
    "            - restricted mating\n",
    "            - diploidy and dominance\n",
    "        - GA versus traditional search and optimization methods\n",
    "            - neural nets\n",
    "            - random search\n",
    "            - gradient search\n",
    "            - iterated search\n",
    "            - simulated annealing\n",
    "    13. Genetic Programming\n",
    "        - growth of genetic programming\n",
    "        - LISP programming language\n",
    "        - functionality of genetic programming\n",
    "            - generation of an individual and population\n",
    "            - creating a random population\n",
    "            - fitness test\n",
    "            - functions and terminals\n",
    "            - the genetic operations\n",
    "            - crossover operation\n",
    "            - mutation operation\n",
    "        - genetic programming in machine learning\n",
    "        - elementary steps in GP\n",
    "            - the terminal set\n",
    "            - the function set\n",
    "            - the fitness function\n",
    "            - the algorithm control parameters\n",
    "            - the termination criterion\n",
    "    14. MATLAB-based swarm intelligence\n",
    "        - biological background\n",
    "        - swarm robots\n",
    "        - stability of swarms\n",
    "        - swarm intelligence\n",
    "        - particle swarm optimization (PSO)\n",
    "        - ant colony optimization\n",
    "- **Machine learning for audio, image and video analysis**\n",
    "    1. introduction\n",
    "    2. From Peception to computation\n",
    "        1. Audio acquisition, representation and storage\n",
    "            - Sound physics, production and perception\n",
    "            - audio acquistion\n",
    "            - audio encoding and storage formats\n",
    "            - Time-domain audio processing\n",
    "        2. Image and video acquisition, representation and storage\n",
    "            - human eye physiology\n",
    "            - image acquisition devices\n",
    "            - color representation \n",
    "            - image formats\n",
    "            - video principles\n",
    "            - MPEG standard\n",
    "    3. Machine Learning\n",
    "        1. Machine learning\n",
    "            - taxonomy of machine learning\n",
    "                - rote learning\n",
    "                - learning from instruction\n",
    "                - learning by analogy\n",
    "            - learning from examples\n",
    "                - supervised learning\n",
    "                - reinforcement learning\n",
    "                - unsupervised learning\n",
    "        2. Bayesian theory of decision\n",
    "            - bayes decision rule\n",
    "            - bayes classifier\n",
    "            - loss function\n",
    "            - zero-one loss function\n",
    "            - discriminany functions\n",
    "            - Gaussian density\n",
    "                - univariate gaussian density\n",
    "                - multivariate gaussian density\n",
    "                - whitening transformation\n",
    "            - discriminant functions for gaussian likelihood\n",
    "                - features are statistically independent\n",
    "                - covariance matrix is the same for all classes\n",
    "                - covariance matrix is not the same for all classes\n",
    "            - receiver operating curves\n",
    "        3. clustering methods\n",
    "            - expectation and maximization algorithm\n",
    "            - basic notions and terminology\n",
    "                - codebooks and codevectors\n",
    "                - quantization error minimization\n",
    "                - entropy maximizaiton\n",
    "                - vector quantization\n",
    "            - k-means\n",
    "            - self-organizing maps\n",
    "            - neural gas topology representing network\n",
    "            - general topographic mapping\n",
    "            - fuzzy clustering algorithms\n",
    "        4. foundation of statistial learning and model selection\n",
    "            - bias-variance dilemma\n",
    "                - bias-variance dilemma for regression\n",
    "                - bias-variance decomposition for classification\n",
    "            - model complexity\n",
    "            - VC dimension and structural risk minimization\n",
    "            - statistical learning/Vapnik-chervonenkis theory\n",
    "            - AIC and BIC criteria\n",
    "            - minimum description length approach \n",
    "        5. supervised neural networks and ensemble methods\n",
    "            - ANNs and neural computation\n",
    "            - ANs\n",
    "            - connections and network architectures\n",
    "            - single-layer networks\n",
    "                - linear discriminant functions and single-layer networks\n",
    "                - linear discriminant and the logistic sigmoid\n",
    "                - generalized linear discriminants and perceptron\n",
    "            - multilayer networks/perceptron\n",
    "            - multilayer networks training\n",
    "                - error back-propagation for feed-forwards networks\n",
    "                - parameter update: the error surface\n",
    "                - parameters update: the gradient descent\n",
    "            - learning vector quantization\n",
    "            - ensemble methods\n",
    "        6. kernel methods\n",
    "            - lagrance method and kuhn tucker theorem\n",
    "            - support vector machines for classification\n",
    "                - optimal hyperplane algorithm\n",
    "                - support vector machine construction\n",
    "                - algorithmics approaches to solve quadratic programming\n",
    "                - sequential minimal optimization\n",
    "                - SVM and regularization methods\n",
    "            - multiclass support vector machines\n",
    "                - one-versus-rest method\n",
    "                - one-versus-one method\n",
    "            - Support vector machines for regression\n",
    "                - regression with quadratic $\\epsilon$-insensitive loss\n",
    "                - kernel ridge regression\n",
    "                - regression with linear $\\epsilon$-insensitive loss\n",
    "            - Gaussian processes\n",
    "            - Kernel Fisher discriminant\n",
    "            - Kernel PCA\n",
    "            - One-Class SVM\n",
    "            - Kernel Clustering Methods\n",
    "        7. markovian models for sequential data\n",
    "            - Hidden markov models\n",
    "            - the three problems\n",
    "            - the likelihood problem and the trellis\n",
    "            - the decoding problem\n",
    "            - the learning problem\n",
    "            - HMM variants\n",
    "            - N-gram models and statistical language modeling\n",
    "            - discounting and smoothing methods for N-gram models\n",
    "            - buidling a language moel with N-grams\n",
    "        8. feature extraction methods and manifold learning methods\n",
    "            - the curse of dimensionality\n",
    "            - data dimensionality\n",
    "            - principal component analysis\n",
    "            - independent component analysis\n",
    "            - multidimensional scaling methods\n",
    "            - manifold learning\n",
    "     4. Applicaitons\n",
    "        1. Speech and handwriting recognition\n",
    "        2. Automatic Face Recognition\n",
    "        3. Video segmentation and keyframe extraction\n",
    "     5. Appendices\n",
    "         1. Statistics\n",
    "             - Fundamentals\n",
    "                 - probability and relative frequency \n",
    "                 - the sample space\n",
    "                 - the addition law\n",
    "                 - conditional probability\n",
    "                 - statistical independence\n",
    "             - random variables\n",
    "                 - fundamentals\n",
    "                 - mathematical expectation\n",
    "                 - variance and covariance\n",
    "         2. Signal processing\n",
    "             - the complex numbers\n",
    "             - the z-transform\n",
    "                 - z-transform properties\n",
    "                 - the fourier transform\n",
    "                 - the discrete fourier transform\n",
    "             - the discrete cosine transform\n",
    "         3. Matrix algebra\n",
    "             - fundamentals\n",
    "             - determinants\n",
    "             - eigenvalues and eigenvectors\n",
    "         4. mathematical foundation of kernel methods\n",
    "             - scalar products, norms and metrics\n",
    "             - positive definite kernels and matrices\n",
    "             - conditionate positive definite kernels matrices\n",
    "             - negative definite kernels and matrices\n",
    "             - relations between positive and negative definite kernels\n",
    "             - metric computation by mercer kernels\n",
    "             - hilbert space representation of positive definite kernels\n",
    "- **Algebraic Geometry and Statistical Learning Theory**\n",
    "    1. Introduction\n",
    "        - basic concepts\n",
    "        - statistical models and learning machines\n",
    "        - statistical estimation methods\n",
    "        - four main formulas\n",
    "    2. Singularity theory\n",
    "        - polynomials and analytic functions\n",
    "        - algebraic set and analytic set\n",
    "        - singularity\n",
    "        - resolution of singularities\n",
    "        - normal crossing singularities\n",
    "        - manifold\n",
    "    3. Algebraic geometry\n",
    "        - ring and ideal\n",
    "        - real algebraic set\n",
    "        - singularities and dimension\n",
    "        - real projective space\n",
    "        - blow-up \n",
    "    4. Zeta function and singular integral\n",
    "        - schwartz distribution\n",
    "        - state density function\n",
    "        - mellin transform\n",
    "        - evaluation of singular integral\n",
    "        - asymptotic expansion and b-function\n",
    "    5. empirical processes\n",
    "        - convergence in law\n",
    "        - function-valued analytic function\n",
    "        - empirical processes\n",
    "        - fluctuation of gaussian processes\n",
    "    6. singular learning theory\n",
    "        - standard form of likelihood ratio function\n",
    "        - evidence and stochastic complexity\n",
    "        - bayes and gibbs estimation\n",
    "        - maximum likelihood and *a posteriori*\n",
    "    7. singular learning machines\n",
    "        - learning coefficient\n",
    "        - three-layered neural networks\n",
    "        - mixture models\n",
    "        - bayesian network\n",
    "        - hidden markov model\n",
    "        - singular learning process\n",
    "        - bias and variance\n",
    "        - non-analystic learning machines\n",
    "    8. singular statistics\n",
    "        - universal optimal learning\n",
    "        - generalized bayes informaiton criterion\n",
    "        - widely applicable information criteria\n",
    "        - singular hypothesis test\n",
    "        - realization of *a posteriori* distribution\n",
    "        - from regular to singular\n",
    "- **Bayesian reasoning and machine learning**\n",
    "    - I. Inference in probabilistic models\n",
    "        1. Probabilistic learning\n",
    "            - probability refresher\n",
    "            - probabilistic reasoning\n",
    "            - prior, likelihood and posterior\n",
    "        2. Basic graph concepts\n",
    "            - graphs\n",
    "            - numerically encoding graphs\n",
    "                - edge list\n",
    "                - adjacency matrix\n",
    "                - clique matrix\n",
    "        3. Belief networks\n",
    "            - the benefits of structure\n",
    "            - uncertain and unreliable evidence\n",
    "            - belief networks\n",
    "            - causality\n",
    "        4. graphical models\n",
    "            - graphical models\n",
    "            - markov networks\n",
    "            - chain graphical models\n",
    "            - factor graphs\n",
    "            - expressiveness of graphical models\n",
    "        5. efficient inference in trees\n",
    "            - marginal inference\n",
    "            - other forms of inference\n",
    "            - inference in multiply connected graphs\n",
    "            - message passing for continuous distribution\n",
    "        6. the junction tree algorithm\n",
    "            - clustering variables\n",
    "            - clique graphs\n",
    "            - junction trees\n",
    "            - constraining a junction tree for singly connected distributions\n",
    "            - junction trees for multiply connected distributions\n",
    "            - the junction tree algorithm\n",
    "            - finding the most likely state\n",
    "            - reabsorption: converting a junction tree to a directed network\n",
    "            - the need for approximations\n",
    "        7. making decisions\n",
    "            - expected utility\n",
    "            - decision trees\n",
    "            - extending bayesian networks for decisions\n",
    "            - solving influence diagrams\n",
    "            - markov decision processes\n",
    "            - temporally unbounded MDPs\n",
    "            - variational inference and planning\n",
    "            - financial matters\n",
    "    - II. Learning in probabilistic models\n",
    "        1. statistics for machine learning\n",
    "            - representing data\n",
    "            - distributions\n",
    "            - classical distributions\n",
    "            - multivariate gaussian\n",
    "            - exponential family\n",
    "            - learning distributions\n",
    "            - properties of maximum likelihood\n",
    "            - learning a gaussian \n",
    "        2. learning as inference\n",
    "            - learning as inference\n",
    "            - Bayesian methods and ML-II\n",
    "            - maximum likelihood training of belief networks\n",
    "            - Bayesian belief network training\n",
    "            - structure learning\n",
    "            - maximum likelihood for undirected models\n",
    "        3. naive bayes\n",
    "            - naive Bayes and conditional independence\n",
    "            - estimation using maximum likelihood\n",
    "            - Bayesian naive Bayes\n",
    "            - tree augmented naive Bayes\n",
    "        4. learning with hidden variables\n",
    "            - Hidden variables and missing data\n",
    "            - Expectation maximization\n",
    "            - Extensions of EM\n",
    "            - A failure case for EM\n",
    "            - Variational Bayes\n",
    "            - Optimising the likelihood by gradient methods\n",
    "        5. Bayesian model selection\n",
    "            - comparing models the Bayesian way\n",
    "            - illustrations: coin tossing\n",
    "            - occam's razor and Bayesian complexity penalisation\n",
    "            - a continuous sample: curve fitting\n",
    "            - approximating the model likelihood\n",
    "            - Bayesian hypothesis testing for outcome analysis\n",
    "    - III. Machine learning\n",
    "        1. Machine learning concepts\n",
    "            - styles of learning\n",
    "                - supervised\n",
    "                - unsupervised\n",
    "                - anomaly detection\n",
    "                - online (sequential) learning\n",
    "                - interacting with the environment\n",
    "                - semi-supervised learning\n",
    "            - supervised learning\n",
    "            - Bayes versus empirical decisions\n",
    "        2. Nearest neighbour classification\n",
    "            - do as your neighbor does\n",
    "            - K-nearest neighbors\n",
    "            - a probabilistic interpretation of nearest neighbors\n",
    "        3. Unsupervised linear dimension reduction\n",
    "            - high-dimensional spaces-low-dimensional manifolds\n",
    "            - principal components analysis\n",
    "            - high-dimensional data\n",
    "            - latent sematic analysis\n",
    "            - PCA with missing data\n",
    "            - matrix decomposition methods\n",
    "            - Kernel PCA\n",
    "            - canonical correlation analysis\n",
    "        4. Supervised linear dimension reduction\n",
    "            - supervised linear projections\n",
    "            - fisher's linear discriminant\n",
    "            - canonical variates\n",
    "        5. Linear models\n",
    "            - introduction: fitting a straight line\n",
    "            - linear parameter models for regression\n",
    "            - the dual representation and kernels\n",
    "            - linear parameter models for classification\n",
    "            - support vector machines\n",
    "            - soft zero-one loss for outlier robustness\n",
    "        6. Bayesian linear models\n",
    "            - regression with additive Gaussian noise\n",
    "            - Classification\n",
    "        7. Gaussian processes\n",
    "            - non-parametric prediction\n",
    "            - Gaussian process prediction\n",
    "            - covariance functions\n",
    "            - analysis of covariance functions\n",
    "            - gaussian processes for classification\n",
    "        8. Mixture models\n",
    "            - density estimation using mixtures\n",
    "            - expectation maximization for mixture models\n",
    "            - the gaussian mixture model \n",
    "            - mixture of experts\n",
    "            - indicator models\n",
    "            - mixed membership models\n",
    "        9. Latent linear models\n",
    "            - factor analysis\n",
    "            - factor analysis: maximum likelihood\n",
    "            - interlude: modelling faces\n",
    "            - probabilistic principal components analysis\n",
    "            - canonical correlation analysis and factor analysis\n",
    "            - independent component analsis\n",
    "        10. Latent ability models\n",
    "            - The Rasch models\n",
    "            - competition models\n",
    "    - IV. Dynamical models\n",
    "        1. Discrete-state Markov models\n",
    "            - markov models\n",
    "            - hidden markov models\n",
    "            - learning HMMs\n",
    "            - related models\n",
    "        2. Continuous-state Markov models\n",
    "            - observed linear dynamical systems\n",
    "            - auto-regressive models\n",
    "            - latent linear dynamical models\n",
    "            - inference\n",
    "            - learning linear dynamical systems\n",
    "            - switching auto-regressive models\n",
    "        3. Switching linear dynamical systems\n",
    "            - the switching LDS\n",
    "            - Gaussian sum filtering\n",
    "            - Gaussian sum smoothing\n",
    "            - reset models\n",
    "        4. Distributed computation\n",
    "            - stochastic Hopfield networks\n",
    "            - learning sequences\n",
    "            - tractable continuous latent variable models\n",
    "            - neural models\n",
    "    - V. Approximate inference\n",
    "        1. sampling\n",
    "            - ancestral sampling\n",
    "            - Gibbs sampling\n",
    "            - Markov chain Monte Carlo (MCMC)\n",
    "            - auxiliary variable methods\n",
    "            - importance sampling\n",
    "        2. deterministic approximate inference\n",
    "            - the Laplace approximation\n",
    "            - Properties Kullback-Leibler variational inference\n",
    "            - Variaitonal bounding using KL(q|p)\n",
    "            - local and KL variational approximations\n",
    "            - mutual information maximization: a KL variational approach\n",
    "            - loopy belief propagation\n",
    "            - expectation propagation\n",
    "            - MAP for Markov networks\n",
    "    - A. Background methematics\n",
    "        1. linear algebra\n",
    "        2. multivariate calculus\n",
    "        3. inequalities\n",
    "        4. optimization\n",
    "        5. multivariate optimization\n",
    "        6. constrained optimization using Lagrance multipliers\n",
    "- **Growing Adaptive Machines - combining development and learning in ANNs**\n",
    "    1. Artificial Neurogenesis: an introduction and selective review\n",
    "    2. A brief introduction to Probabilistic Machine Learning and its relation to Neuroscience\n",
    "    3. **Evolving Culture versus local minima (Y bengio)**\n",
    "    4. Learning Sparse features with an auto-associator\n",
    "    5. HyperNEAT: the first Fiver years\n",
    "    6. Using the genetic regulatory evolving ANs (GReaNs) Platform for Signal Processing, Animat Control, and Artificial Multicellular Development\n",
    "    7. Constructing complex systems via activity-driven unsupervised Hebbian self-organizaiton\n",
    "    8. Neuro-centric and holocentric approaches to the evolution of developmental neural networks\n",
    "    9. Artificial evolution of plastic neural networks: a few key concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Machine Learning** (mitchell)\n",
    "    1. Introduction\n",
    "        - well-posed learning problems\n",
    "        - designing a learning system\n",
    "        - perspectives and issues in machine learning\n",
    "    2. Concept Learning and the general-to-specific ordering\n",
    "        - a concept learning task\n",
    "        - concept learning as search\n",
    "        - Find-S: Finding a maximally specific hypotheses\n",
    "        - Version spaces and the candidate-elimination algorithm\n",
    "        - remarks on vesion spaces and cadidate-elimination\n",
    "        - inductive bias\n",
    "    3. Decision tree learning\n",
    "        - decision tree representation\n",
    "        - appropriate problems for decision tree learning\n",
    "        - the basic decision tree learning algorithm\n",
    "        - hypothesis space search in decision tree learing\n",
    "        - inductive bias in decision tree learning\n",
    "        - issues in decision tree learning\n",
    "    4. Artificial Neural networks\n",
    "        - neural network representations\n",
    "        - appropriate problems for neural network learning\n",
    "        - perceptrons\n",
    "        - multilayer networks and the backpropagation algorithm\n",
    "        - remarks on the backpropagation algorithm\n",
    "        - alternative error functions\n",
    "        - alternative error minimization procedures\n",
    "        - recurrent networks\n",
    "        - dynamically modifying network structure\n",
    "    5. Evaluating hypotheses\n",
    "        - estimating hypothesis accuracy\n",
    "        - basics of sampling theory\n",
    "        - error estimation and estimating binomial proportions\n",
    "        - the binomial distribution\n",
    "        - mean and variance\n",
    "        - estimators, bias and variance\n",
    "        - confidence intervals\n",
    "        - two-sided and one-sided bounds\n",
    "        - general approach for deriving confidence intervals\n",
    "        - difference in error of two hypotheses\n",
    "        - comparing learning algorithms\n",
    "    6. Bayesian learning\n",
    "        - bayes theorem\n",
    "        - bayes theorem and concept learning\n",
    "        - maximum likelihood and least-squared error hypotheses\n",
    "        - maximum likelihood hypotheses for predicting probabilities\n",
    "        - minimum description length principle\n",
    "        - bayes optimal classifier\n",
    "        - Gibbs algorithm\n",
    "        - Naive Bayes classifier\n",
    "        - Bayesian belief networks\n",
    "           - conditional independence\n",
    "           - representation\n",
    "           - inference\n",
    "           - learning bayesian belief networks\n",
    "           - gradient ascent training of bayesian networks\n",
    "           - learning the structure of bayesian networks\n",
    "        - The EM Algorithm\n",
    "    7. Computational learning theory\n",
    "        - probably learning an approximately correct hypothesis\n",
    "        - sample complexity for finite hypothesis spaces\n",
    "        - sample complexity for infinite hypothesis spaces\n",
    "        - the mistake bound model of learning\n",
    "    8. Instance-based learning\n",
    "        - k-Nearest neighbor learning\n",
    "        - locally weighted regression\n",
    "        - radial basis functions\n",
    "        - case-based reasoning\n",
    "        - remarks on lazy and eager learning\n",
    "    9. genetic algorithms\n",
    "        - representing hypotheses\n",
    "        - genetic operators\n",
    "        - fitness function and selection\n",
    "        - hypothesis space search\n",
    "        - population evolution and the scheme theorem\n",
    "        - genetic programming\n",
    "        - models of evolution and learning\n",
    "        - parallelizing genetic algorithms\n",
    "    10. Learning sets of rules\n",
    "        - sequential covering algorithms\n",
    "        - learning rule sets: summary\n",
    "        - learning first-order rules\n",
    "        - learning sets of first-order rules: FOIL\n",
    "        - induction as inverted deduction\n",
    "        - inverting resolution\n",
    "    11. Analytical learning\n",
    "        - learning with perfect domain theories\n",
    "        - remaks on explanation-based learning\n",
    "        - explanation-based learning of search control knowledge\n",
    "    12. combining inductive and analytical learning\n",
    "        - inductive-analytical approaches to learning\n",
    "        - using prior knowledge to initialize the hypothesis\n",
    "        - using prior knowledgeto alter the search objective\n",
    "        - using prior knowledge to augment search operators\n",
    "    13. reinforcement learning\n",
    "        - the learning task\n",
    "        - Q learning\n",
    "        - the Q function\n",
    "        - nondeterministic rewards and actions\n",
    "        - temporal difference learning\n",
    "        - generalizing from examples\n",
    "        - relationship to dynamic programming\n",
    "- **Autonomous learning systems - from data streams to knowledge in real-time**\n",
    "    1. Introduction\n",
    "        - autonomous systems\n",
    "        - the role of machine learning in autonomous systems\n",
    "        - system identification - an abstract model of the real world\n",
    "            - system structure identification\n",
    "            - parameter identification\n",
    "            - novelty detection, outliers and the link to structure innovation\n",
    "        - online versus offline identification\n",
    "        - adaptive and evolving systems\n",
    "        - evolving or evolutionary systems\n",
    "        - supervised versus unsupervised learnind\n",
    "    2. Fundamentals\n",
    "        1. Fundamentals of probability theory\n",
    "            - randomness and determinism\n",
    "            - frequentistic versus belief-based approach\n",
    "            - probability densities and moments\n",
    "            - density estimation - kernel-based approach\n",
    "            - recursive density estimation (RDE)\n",
    "            - detecting novelties/anomalies/outlier using RDE\n",
    "        2. Fundamentals of machine learning and pattern recognition\n",
    "            - preprocessing\n",
    "                - normalization and standardization\n",
    "                - orthogonalization of inputs/features - rPCA method\n",
    "            - clustering\n",
    "                - proximity measures and clusters shape\n",
    "                - offline methods\n",
    "                - evolving clustering methods\n",
    "            - classification\n",
    "        3. Fundamentals of fuzzy systems theory\n",
    "            - fuzzy sets\n",
    "            - fuzzy systems, fuzzy rules\n",
    "            - fuzzy systems with nonparametric antecedent (AnYa)\n",
    "            - FRB (offline) classifiers\n",
    "            - neurofuzzy systems\n",
    "            - state space perspective\n",
    "    3. Methodology of autonomous learning systems\n",
    "        1. evolving system structure from streaming data\n",
    "            - defining system structure based on *prior* knowledge\n",
    "            - data space partitioning\n",
    "            - normalization and standardization of streaming data in an evolving environment\n",
    "            - autonomous monitoring of the structure quality\n",
    "            - short- and long-term focal points and submodels\n",
    "            - simplification and interpretability\n",
    "        2. autonomous learning parameters of the local submodels\n",
    "            - learning parameters of local submodels\n",
    "            - global versus local learning\n",
    "            - evolving systems structure recursively\n",
    "            - learning modes\n",
    "            - robustness to outliers in autonomous learning\n",
    "        3. autonomous predictors, estimators, filters, inferential sensors\n",
    "            - predictors, estimators, filters - problem formulation\n",
    "            - nonlinear regression\n",
    "            - time series\n",
    "            - autonomous learning sensors\n",
    "        4. autonomous learning classifiers\n",
    "            - classifying data streams\n",
    "            - why adapt the classifier structure?\n",
    "            - architecture of autonomous classifiers of the family AutoClassify\n",
    "            - learning AutoClassify from streaming data\n",
    "        5. autonomous learning controllers\n",
    "            - indirect adaptive control scheme\n",
    "            - evolving inverse plant model from online streaming data\n",
    "            - evolving fuzzy controller structure from online streaming data\n",
    "        6. collaborative autonomous learning systems\n",
    "            - distributed intelligence\n",
    "            - autonomous collaborative learning\n",
    "            - collaborative autonomous clustering\n",
    "            - collaborative autonomous predictors, estimators, filters and Autosense by a team of ALSs\n",
    "            - superposition of local submodels\n",
    "    4. Applications of ALS\n",
    "        1. autonomous learning sensors for chemical and pretrochemical industries\n",
    "        2. autonomous learning systems in mobile robotics\n",
    "            - the mobile robot pioneer 3DX\n",
    "            - autonmous classifier for landmark recognition\n",
    "            - autonmous leader follower\n",
    "        3. autonmous novelty detection and object tracking in video streams\n",
    "            - problem definition\n",
    "            - background subtraction and KDE for detecting visual novelties\n",
    "            - detectign visual novelties with the RDE method\n",
    "            - object identification in image frames using RDE\n",
    "            - real-time tracking in video streams using ALS\n",
    "        4. modelling evolving user behavior with ALS\n",
    "            - user behavior as an evolving phenomenon\n",
    "            - desining the user behavior profile\n",
    "    5. Appendices\n",
    "        1. mathematical foundations\n",
    "            - probability distributions\n",
    "            - basic matrix properties\n",
    "        2. pseudocode of the basic algorithms\n",
    "- ** reinforcement learning - an introduction**\n",
    "     - I. The problem\n",
    "         1. introduction\n",
    "             - elements of reinforcement learning\n",
    "         2. evaluative feedback\n",
    "             - an n-armed Bandit problem\n",
    "             - action-value methods\n",
    "             - softmax action selection\n",
    "             - evaluation versus instruction\n",
    "             - incremental implementation\n",
    "             - tracking a nonstationary problem\n",
    "             - optimistic initial values\n",
    "             - reinforcement comparison\n",
    "             - pursuit methods\n",
    "             - associative search\n",
    "         3. the reinforcement learning problem\n",
    "             - the agent-environment interface\n",
    "             - goals and rewards\n",
    "             - returns\n",
    "             - a unified notation for episodic and continual tasks\n",
    "             - the markov property\n",
    "             - markov decision processes\n",
    "             - value functions\n",
    "             - optimal value functions\n",
    "             - optimality and approximation\n",
    "     - II. Elementary methods\n",
    "         1. dynamic programming\n",
    "             - policy evaluation\n",
    "             - policy improvement\n",
    "             - policy interation\n",
    "             - value iteration\n",
    "             - asynchronous dynamic programming\n",
    "             - generalized policy iteration\n",
    "             - efficiency of DP\n",
    "         2. Monte carlo methods\n",
    "             - monte carlo policy evaluation\n",
    "             - monte carlo estimation of action values\n",
    "             - monte carlo control\n",
    "             - on-policy monte carlo control\n",
    "             - evaluating one policy while following another\n",
    "             - off-policy monte carlo control\n",
    "             - incremental implementation \n",
    "         3. temporal difference learning\n",
    "             - td precition\n",
    "             - optimality of TD(0)\n",
    "             - sarsa: on-policy TD control\n",
    "             - Q-learning: off-policy TD control\n",
    "             - actor-critic methods\n",
    "             - R-learning for undiscounted continual tasks\n",
    "             - games, after states, and other special cases\n",
    "     - III. a unified view\n",
    "         1. eligibility traces\n",
    "         2. generalization and function approximation\n",
    "             - value prediction with function approximation\n",
    "             - gradient-descent methods\n",
    "             - linear methods\n",
    "                 - coarse coding\n",
    "                 - tile coding\n",
    "                 - radial basis functions\n",
    "                 - kanerva coding\n",
    "             - control with function approximation \n",
    "             - off-policy bootstrapping\n",
    "             - should we bootstrap?\n",
    "         3. planning and learning\n",
    "             - models and planning\n",
    "             - integrating planning, acting and learning\n",
    "             - when the model is wrong\n",
    "             - prioritized sweeping\n",
    "             - full s. sample backups\n",
    "             - trajectory sampling\n",
    "             - heuristic search\n",
    "         4. dimensions\n",
    "         5. case studies\n",
    "- **Simulated Evolution and learning**\n",
    "    1. evolutionary learning\n",
    "        1. modelling behavior cycles for life-long learning in motivated agents\n",
    "        2. breaking the synaptic dogma: evolving a neuro-inspired developmental network\n",
    "        3. a new approach to adapting control parameters in differential evolution algorithm\n",
    "        4. a nocal genetic algorithm with orthogonal prediction for global numerical optimization\n",
    "        5. phylogeny inference using a multi-objective evolutionary algorithm with indirect representation\n",
    "        6. evolved look-up tables for simulated DNA controlled robots\n",
    "        7. multi-objective improvement of software using co-evolution and smart seeding\n",
    "        8. policy evolution with grammatical evolution\n",
    "        9. a pso based Adaboost approach to objet detection\n",
    "        10. adaptive non-uniform distribution of quantum particles in mQSO\n",
    "        11. genetically evolved fuzzy rule-based classifiers and application to automotive classification\n",
    "        12. improving XCS performance by distribution\n",
    "        13. evolving an ensemble of neural networks using artificial immune systems\n",
    "        14. improving the performance and scalability of differential evolution\n",
    "        15. a fuzzy-GA decision support system for enhancing postponement strategies in supply chain management\n",
    "    2. evolutionary optimization\n",
    "        1. solving the delay-constrained capacitated minimum spanning tree problem using a dandelion-encoded evolutionary alorithm\n",
    "        2. generalized extremal optimization for solving multiprocessor task scheduling problem\n",
    "        3. improving NSGA-II algorithm based on minimum spanning tree\n",
    "        4. an island based hyprid evolutionary algorithm for optimization\n",
    "        5. a particle swarm optimization based algorithm for fuzzy bilevel decision making with objective-shared followers\n",
    "        6. eference point-based particle based swarm optimization using a steady-state approach\n",
    "        7. genetic algorithm based methods for identification of health risk factors aimed at preventing metabolic syndrome\n",
    "        8. extremal optimization and bin packing\n",
    "        9. extremal optimization with a penalty approach for the multidimensional knapsack problem\n",
    "        10. a generator for multimodal test functions with multiple global optima\n",
    "        11. choosing leaders for multi-objective PSO algorithms using differential evolution\n",
    "        12. comparison between genetic algorithm and genetic programming performance for photomosaic generation\n",
    "        13. parameter tuning of real-valued crossover operators for statistics preservation\n",
    "        14. hybrid particle swarm optimization based on thermodynamic\n",
    "        15. multiagent evolutionary algorithm for T-coloring problem\n",
    "        16. non-photorealisic rendering using genetic programming\n",
    "        17. use of local ranking incellular genetic algorithms with two neighborhood structures\n",
    "        18. information theoretic classification problems for metaheuristics\n",
    "        19. task decomposition for optimization problem solving\n",
    "        20. discussion of search strategy for multi-objective genetic algorithm with consideration of accuracy and broadness of pareto optimal solution\n",
    "        21. discussion of offspring generation method for interactive genetic algorithms with consideration of multimodal preference\n",
    "        22. solving very difficult japanese puzzles with a hybrid evolutionary-logic algorithm\n",
    "        23. joint multicast routing and channel assignment in multirado multichannel wireles mesh networks using simulated annealing\n",
    "        24. general game playing ants\n",
    "        25. a generalized approach to construct benchmark problems for dynamic optimization\n",
    "        26. a study on the performance of substitute distance based approaches for evolutionary many objective optimization\n",
    "        27. performance evaluation of an adaptive ant colony optimization applied to single machine scheduling\n",
    "        28. robust optimization by $\\Sigma$-ranking on high dimensional objective spaces\n",
    "        29. an evolutionary method for natural language to SQL translation\n",
    "        30. attributes of dynamic combinatorial optimization\n",
    "        31. a weighted local sharing technique for multimodel optimization\n",
    "    3. Hybrid learning\n",
    "        1. hybrid genetic programming for optimal approximation of high order and sparse linear systems\n",
    "        2. genetic vector quantizer design on reconfigurable hardware\n",
    "        3. pattern learning and decision making in a photovltaic system\n",
    "        4. using numerical simplification to control bloat in genetic programming\n",
    "        5. horn query leanring with multiple refinement\n",
    "        6. evolving digitial circuits in an industry standard hardware descripiton language\n",
    "        7. parameterized indexed FOR-loops in genetic programming and regular binary pattern strings\n",
    "        8. hierarchical fuzzy control for the inverted pendulum over the set of initial conditions\n",
    "        9. genetic programming for feature ranking in classification problems\n",
    "        10. time series prediction with evolved, composite echo state networks\n",
    "    4. adaptive systems\n",
    "        1. genetic synthesis of software architecture\n",
    "        2. dual phase evolution and self-organization in networks\n",
    "        3. heterogeneous payoffs and social diversity in the spatial prisoner's dilemma game\n",
    "    5. theoretical issues in evolutionary computation\n",
    "        1. crossover can be constructive when computing unique input output sequences\n",
    "    6. real-world applications of evolutionary computation techniques\n",
    "        1. power electronic circuits design: a particle swarm optimization approach\n",
    "        2. computational intelligence in radio astronomy: using computational techniques to tune geodesy models\n",
    "        3. an efficient hybrid algorithm for optimization of discrete structures\n",
    "        4. evolutionary multi-objective optimization for biped walking\n",
    "        5. a method for assigning men and women with good affinity to matchmaking parties through interactive evolutionary computation\n",
    "- **Compressed sensing and sparse filtering**\n",
    "    1. introduction to compressed sensing and sparse filtering\n",
    "    2. the geometry of compressed sensing\n",
    "    3. sparse signal recovery with exponential-family noise\n",
    "    4. nuclear norm optimizaiton and its applicaiton to observation model specification\n",
    "    5. nonnegative tensor decomposition\n",
    "    6. sub-nyquist sampling and compressed sensing in cognitive radio networks\n",
    "    7. sparse nonlinear MIMO filtering and identification\n",
    "    8. optimization viewpoint on kalman smoothing with applications to robust and sparse estimation\n",
    "    9. compressive system identification\n",
    "    10. distributed approximation and tracking using selective gossip\n",
    "    11. recursive reconstruction of sparse signal sequences\n",
    "    12. estimation of time-varying sparse signals in sensor networks\n",
    "    13. sparsity and compressed sensing in mono-static and multi-static radar imaging\n",
    "    14. structured sparse Bayesian modelling for audio restoration\n",
    "    15. sparse representations for speech recognition\n",
    "- **Compressed sensing - theory and applications**\n",
    "    1. introduction compressed sensing\n",
    "    2. second-generation sparse modeling: structured and collaborative signal analysis\n",
    "    3. Xampling: compressed sensing of analog signals\n",
    "    4. sampling at the rate of innovation: theory and applications\n",
    "    5. introduction to the non-asymptotic analysis of random matrices\n",
    "    6. adaptive sensing for sparse recovery\n",
    "    7. fundamental thresholds in compressed sensing: a high-dimensional geometry approach\n",
    "    8. greedy algorithms for compressed sensing\n",
    "    9. graphical models concepts in compressed sensing\n",
    "    10. finding needles in compressed haystacks\n",
    "    11. data separation by sparse representations\n",
    "    12. face recognition by sparse representation\n",
    "- **Sparse and redundant representations - from theory to applications in signal and image processing**\n",
    "    - I. sparse and redundant representations - theoretical and numerical foundations\n",
    "        1. Prologue\n",
    "            - underdetermined linear systems\n",
    "            - regularization\n",
    "            - the temptation of convexity\n",
    "            - a closer look at $\\mathscr{l}_1$ minimization\n",
    "            - conversion of ($P_1$) to linear programming\n",
    "            - promoting sparse soltions\n",
    "            - the $\\mathscr{l}_0$-Norm and implications\n",
    "            - the ($P_0$) probelm - our main interest\n",
    "            - the signal processing perspective\n",
    "        2. Uniqueness and uncertainty\n",
    "            - treating the two-ortho case\n",
    "                - an uncertainty principle\n",
    "                - uncertainty of redundant solutions\n",
    "                - from uncertainty to uniqueness\n",
    "            - uniqueness analysis for the general case\n",
    "            - constructing grassmannian matrices\n",
    "        3. pursuit algorithms - practice\n",
    "            - greedy algorithms\n",
    "            - convex relaxation techniques\n",
    "        4. pursuit algorithms - guarantees\n",
    "            - back to the two-ortho case\n",
    "            - the general case\n",
    "            - the role of the sign-pattern\n",
    "            - tropp's exact recovery condition\n",
    "        5. from exact to approximate solutions\n",
    "            - general motivation\n",
    "            - stability of the Sparsest solution\n",
    "            - Pursuit algorithms\n",
    "            - the unitary case\n",
    "            - performance of pursuit algorithms\n",
    "        6. iterative-shrinkage algorithms\n",
    "            - background\n",
    "            - the unitary case - a source of inspiration\n",
    "            - developing iterative-shrinkage algorithms\n",
    "            - acceleration using line-search and SESOP\n",
    "            - iterative-shrinkage algorithms: tests\n",
    "        7. Towards average performance analysis\n",
    "            - a glimpse into probabilistic analysis\n",
    "            - average performance of thresholding\n",
    "        8. the dantzip-selector algorithm\n",
    "            - dantzig-selector versus basis-pursuit\n",
    "            - the unitary case\n",
    "            - revisiting the restricted isometry machinery\n",
    "            - dantzig-selector performance guaranty\n",
    "            - dantzig-selector in practice\n",
    "    - II. from theory to practice - signal and image processing applications\n",
    "        1. sparsity-seeking methods in signal processing\n",
    "            - priors and transforms for signals\n",
    "            - the sparse-land model\n",
    "            - geometric interpretation of sparse-land\n",
    "            - processing of sparsely-generated signals\n",
    "            - analysis versus synthesis signal modeling\n",
    "        2. image deblurring - a case study\n",
    "        3. MAP versus MMSE estimation\n",
    "        4. the quest for a dictionary\n",
    "            - choosing versus learning\n",
    "            - dictionary-learning algorithms\n",
    "            - training structured dictionaries\n",
    "        5. Image compression - facial images\n",
    "        6. image denoising\n",
    "        7. other applications\n",
    "            - image inpainting and impulsive noise removal\n",
    "            - image scale-up\n",
    "- **from animals to robots and back - reflections on hard problems in the study of cognition**\n",
    "    1. Bringing together different pieces to better understand whole minds\n",
    "    2. arron sloman: a bright tile in AI's mosaic\n",
    "    3. losing control within the H-Cogaff architecture\n",
    "    4. acting on the world: understanding how agents use information to guide their action\n",
    "    5. a proof and some representations\n",
    "    6. what does it mean to have an architecture?\n",
    "    7. virtual machines: nonreductionaist bridges beween the functional and the physical\n",
    "    8. building for the future: architectures for the next generation of intelligent robots\n",
    "    9. what vision can, can't and should do\n",
    "    10. the rocky road from Hume to Kant: correlations and theories in robots and animals\n",
    "    11. combining planning and action, lessons from robots and the natural world\n",
    "    12. developing expertise with objective knowledge: motive generators and productive practice\n",
    "    13. from cognitive science to data mining: the first intelligence amplifier\n",
    "    14. modelling user linguistic communicative competences for individual and collaborative learning\n",
    "    15. loop-closing semantics\n",
    "- **A concise introduction to multiagent systems and distributed artificial intelligence**\n",
    "    1. Introduction\n",
    "    2. Rational agents\n",
    "        - agents as rational decision makers\n",
    "        - observable worlds and the markov property\n",
    "        - stochastic transitions and utilities\n",
    "    3. Strategic Games\n",
    "        - game theory\n",
    "        - strategic games\n",
    "        - iterarted elimination of dominated actions\n",
    "        - nash equilibrium\n",
    "    4. Coordination\n",
    "        - coordination games\n",
    "        - social conventions\n",
    "        - roles\n",
    "        - coordination graphs\n",
    "    5. Partial observability\n",
    "        - thinking interactively\n",
    "        - common knowledge\n",
    "        - partial observability and actions\n",
    "    6. Mechanism design\n",
    "        - self-interested agents\n",
    "        - the mechanism design problem\n",
    "        - the revelation principle\n",
    "        - the vickrey-clarke-groves mechanism\n",
    "    7. Learning\n",
    "        - reinforcement learning\n",
    "        - markov decision processes\n",
    "        - markov games\n",
    "        - the problem of exploration\n",
    "- **creating brian-like intelligence: from basic principles to complex intelligent systems**\n",
    "    1. creating brain-like intelligence\n",
    "    2. **from complex networks to intelligent systems (sporns)**\n",
    "    3. stochastic dynamics in the brain and probabilistic decision-making\n",
    "    4. formal tools for the analysis of brain-like structures and dynamics\n",
    "    5. morphological computation - connecting brain, body and environment\n",
    "    6. trying to grasp a sketch of a brain for grasping\n",
    "    7. learning actions through imitation and exploration: towards humanoid robots that learn from actions\n",
    "    8. towards learning by interaction\n",
    "    9. planning and moving in dynamic environments: a statistical machine learning approach\n",
    "    10. towards cognitive robotics\n",
    "    11. approaches and challenges for cognitive vision systems\n",
    "    12. some requirements for human-like robots: why the recent over-emphasis on emodiment has held up progress (a. sloman)\n",
    "    13. co-evolution of rewards and meta-parameters in embodied evolution\n",
    "    14. active vision for goal-oriented humanoid robot walking\n",
    "    15. cognitive adequacy in brain-like intelligence\n",
    "    16. basal ganglia models for autonomous behavior learning\n",
    "- **from animals to animats 13**\n",
    "    1. Animat Approach and methodology\n",
    "        - a role for sleep in artificial cognition through deferred restructuring of experience in autonomous machines\n",
    "        - time in consciousness, memory and human-robot interaction\n",
    "        - non-representational sensorimotor knowledge\n",
    "    2. Perception and motor control\n",
    "        - self-exploration of the stumpy robot with predictive information maximization\n",
    "        - detecting the vibration in the artificial web inspired by the spider\n",
    "        - modelling reaction times in non-linear classification tasks\n",
    "        - multiple decoupled CPGs with local sensory feedback for adaptive locomotion behaviors of bio-inspired walking robots\n",
    "        - the role of a cerebellum-driven perceptual prediction within a robot postural task\n",
    "        - biomemetic agent based modelling using male frog calling behavior as a case study\n",
    "    3. Navigation and internal world models\n",
    "        - snapshot homing navigation based on edge features\n",
    "        - ground-nesting insects could use visual tracking for monitoring nest position during early flight\n",
    "        - adaptive landmark-based navigation system using learning techniques\n",
    "        - robustness study of a multimodel compass inspired from HD-cells and dynamic neural fields\n",
    "    4. learning and adaptation\n",
    "        - developmental dynamics of RNNPB: new insight about infant action developments\n",
    "        - simulating the emergence of early physical and social interactions: a developmental route through low level visuomotor learning\n",
    "        - intrinsically motivated decision making for situated, goal-driven agents\n",
    "        - an anti-Hebbian learning rule to represent drive motivations for reinforcement learning\n",
    "        - **unsupervised learning for sensory primitives from optical flow fields**\n",
    "        - reinforcement driven shaping of sequence learning in neural dynamics\n",
    "        - **rapid humanoid motion learing through coordinated, parallel evolution**\n",
    "    5. Evolution\n",
    "        - programmable self-assembly with chained soft cells: an algorithm to fold into 2-D shapes\n",
    "        - voxel robot: a pneumatic robot with deformable morphology\n",
    "        - task-driven evolution of modulra self-reconfigurable robots\n",
    "        - a bacterial-based algorithm to simulate complex adaptive systems\n",
    "        - **online evolution of deep convolutional network for vision-based reinforcement learning** (schmidhuber)\n",
    "    6. Collective and social behavior\n",
    "        - a swarm robotics approach to task allocation under soft deadlines and negligible switching costs\n",
    "        - supervised robot groups with reconfigurable formation: theory and simulations\n",
    "        - coupling learning capability and local rules for the improvement of the objects' aggregation task by a cognitive multi-robot system\n",
    "        - honeybee-inspired quality monitoring of routing paths in mobile ad hoc networks\n",
    "        - human inspiration and comparison for monitoring strategies in a robotic convoy task\n",
    "        - animal social behavior: a visual analysis\n",
    "        - crowd emotion detection using dynamic probabilistic models\n",
    "- **Artificial Intellience - A new synthesis**\n",
    "    1. Ractive Machines\n",
    "        1. Stimulus-response agents\n",
    "            - perception and action\n",
    "                - perception \n",
    "                - action\n",
    "                - Boolean algebra\n",
    "                - classes and forms of Boolean functions\n",
    "            - representing and implementing action functions\n",
    "                - production systems\n",
    "                - networks\n",
    "                - the subsumption architecture\n",
    "        2. Neural networks\n",
    "            - Training single TLUs\n",
    "                - TLU geometry\n",
    "                - augmented vectors\n",
    "                - gradient descent methods\n",
    "                - the widrow-hoff procedure\n",
    "                - the generalized delta prodedure\n",
    "                - the error-correction procedure\n",
    "            - Neural networks\n",
    "                - motivation\n",
    "                - notation\n",
    "                - the backpropagation method\n",
    "                - computing weight changes in the final layer\n",
    "                - computing changes to the weights in intermediate layers\n",
    "            - generalization, accuracy and overfitting\n",
    "        3. Machine evolution\n",
    "            - evolutionary computation\n",
    "            - genetic programming\n",
    "                - program representation in GP\n",
    "                - the GP process\n",
    "                - evolving a wall-following robot\n",
    "        4. State machines\n",
    "            - representing the environment by feature vectors\n",
    "            - elman networks\n",
    "            - iconic representations\n",
    "            - blackboard systems\n",
    "        5. robot vision\n",
    "            - steering an automobile\n",
    "            - two stages of robot vision\n",
    "            - image processing\n",
    "                - averaging\n",
    "                - edge enhancement\n",
    "                - combining edge enhancement with averaging\n",
    "                - region finding\n",
    "                - using image attributes other than intensity\n",
    "            - scene analysis\n",
    "                - interpreting lines and curves in the image\n",
    "                - model-based vision\n",
    "            - stereo vision and depth information\n",
    "    2. Search in state spaces\n",
    "        1. agents that plan\n",
    "            - memory versus computation\n",
    "            - state-space graph\n",
    "            - searching explicit state spaces\n",
    "            - feature-based state spaces\n",
    "            - graph notation\n",
    "        2. uninformed search\n",
    "            - formulating the state space\n",
    "            - components of implicit state-space graphs\n",
    "            - breadth-first search\n",
    "            - depth-first of backtracking search\n",
    "            - iterative deepening\n",
    "        3. heuristic search\n",
    "            - using evaluation functions\n",
    "            - a general graph-searching algorithms (algorithm A\\*)\n",
    "            - heuristic functions and search efficiency\n",
    "        4. planning, acting and learning\n",
    "            - the sense/plan/act cycle\n",
    "            - approximate search\n",
    "                - island-driven search\n",
    "                - hierarchical search\n",
    "                - limited-horizon search\n",
    "                - cycles\n",
    "                - building reactive procedures\n",
    "            - learning heuristic functions\n",
    "                - explicit graphs\n",
    "                - implicit graphs\n",
    "            - rewards instead of goals\n",
    "        5. alternative search formulations and applications\n",
    "            - assignment problems\n",
    "            - constructive methods\n",
    "            - heuristic repair\n",
    "            - function optimization\n",
    "        6. adversarial search \n",
    "            - two-agent games\n",
    "            - the minimax procedure\n",
    "            - the alpha-beta procedure\n",
    "            - the search efficiency of the alpha-beta procedure\n",
    "            - other important matters\n",
    "            - games of chance\n",
    "            - learning evauation functions\n",
    "    3. Knowledge Representation and Reasoning\n",
    "        1. the propositional calculus\n",
    "            - using constraints on feature vectors\n",
    "            - the language\n",
    "            - rules of inference\n",
    "            - definition of proof\n",
    "            - semantics\n",
    "            - soundness and completeness\n",
    "            - the PSAT problem\n",
    "        2. resolution in the propositional calculus\n",
    "            - a new rule of inference: resolution\n",
    "            - converting arbitrary wffs to conjunctions of clauses\n",
    "            - resolution refutations\n",
    "            - resolution refutation search strategies\n",
    "            - horn clauses\n",
    "        3. the predicate calculus\n",
    "            - motivation\n",
    "            - the language and its syntax\n",
    "            - semantics\n",
    "            - quantification\n",
    "            - semantics of quntifiers\n",
    "            - predicate calculus as a language for representing knowledge\n",
    "        4. resolution in the predicate calculus\n",
    "            - unification\n",
    "            - predicate-calculus resolution\n",
    "            - completeness and soundness\n",
    "            - converting arbitrary wffs to clause form\n",
    "            - using resolution to prove theorems\n",
    "            - answer extraction\n",
    "            - the equality predicate\n",
    "        5. knowledge-based systems\n",
    "            - confronting the real world\n",
    "            - reasoning using horn clauses\n",
    "            - maintenance in dynamics knowledge bases\n",
    "            - rule-based expert systems\n",
    "            - rule learning\n",
    "        6. representing commonsense knowledge\n",
    "            - the commonsense world\n",
    "            - time\n",
    "            - knowledge representation by networks\n",
    "        7. reasoning with uncertain information\n",
    "            - review of probability theory\n",
    "            - probabilistic inference\n",
    "            - bayes networks\n",
    "            - patterns of inference in bayes networks\n",
    "            - uncertain evidence\n",
    "            - D-separation\n",
    "            - probabilistic inference in polytrees\n",
    "        8. learning and acting with bayes nets\n",
    "            - learning Bayes nets\n",
    "            - probabilistic inference and action\n",
    "    4. Planning Methods based on logic \n",
    "        1. the situation calculus\n",
    "        2. planning\n",
    "    5. Communication and integration \n",
    "        1. multiple agents\n",
    "        2. communication among agents\n",
    "        3. agent architectures\n",
    "            - three-level architectures\n",
    "            - goal arbitration\n",
    "            - the triple-tower architecture\n",
    "            - bootstrapping\n",
    "- **intelligent autonomous robotics - a robot soccer case study**\n",
    "    1. Introduction\n",
    "    2. The class\n",
    "    3. initial behaviors\n",
    "    4. Vision\n",
    "        - camera settings\n",
    "        - color segmentation\n",
    "        - region building and merging\n",
    "        - object recognition with bounding boxes\n",
    "        - position and bearing of objects\n",
    "        - visual opponent modeling\n",
    "    5. Movement \n",
    "        - Walking\n",
    "            - basics\n",
    "            - forward kinematics\n",
    "            - inverse kinematics\n",
    "            - general walking structure\n",
    "            - omnidirectional control\n",
    "            - tilting the body forward\n",
    "            - tuning the parameters\n",
    "            - odometry calibration\n",
    "        - General movement\n",
    "            - movement module\n",
    "            - movement interface\n",
    "            - high-level control\n",
    "        - learning movement tasks\n",
    "            - forward gait\n",
    "            - ball acquisition\n",
    "    6. Fall detection\n",
    "    7. kicking\n",
    "        - creating the critical action\n",
    "        - integrating the critical aciton in the walk\n",
    "    8. localization\n",
    "        - background\n",
    "            - basic monte carlo localization\n",
    "            - mcl for vision-based legged robots\n",
    "        - enhancements to the basic approach\n",
    "            - landmark histories\n",
    "            - distance-based updates\n",
    "            - extended motion model\n",
    "        - experimental setup and results\n",
    "    9. Communication\n",
    "        - initial robot-to-robot communication\n",
    "        - message types\n",
    "        - knowing which robots are communicating\n",
    "        - determining when a teammate is \"dead\"\n",
    "    10. General architecture\n",
    "    11. Global map\n",
    "        - maintaining location data\n",
    "        - information from teammates\n",
    "        - providing a high-level interface\n",
    "    12. behaviors\n",
    "        - goal scoring\n",
    "            - initial solution\n",
    "            - incorporating localization\n",
    "            - a finite state machine\n",
    "    13. Coordination\n",
    "        - dibs\n",
    "            - relevant data\n",
    "            - thrashing \n",
    "            - stabilization\n",
    "            - taking the average\n",
    "            - aging\n",
    "            - calling the ball\n",
    "            - support distance\n",
    "        - final strategy\n",
    "            - roles\n",
    "            - supporter behavior\n",
    "            - defender behavior\n",
    "            - dynamic role assigment\n",
    "    14. simulator\n",
    "    15. UT assist\n",
    "- **artificial intelligence - a modern approach**\n",
    "    1. introduction\n",
    "    2. intelligent agents\n",
    "    3. solving problems by searching\n",
    "    4. beyond classical search \n",
    "    5. adversarial search\n",
    "    6. logical agents\n",
    "    7. constraint satisfaction problems\n",
    "    8. first-order logic\n",
    "    9. inference in first-order logic\n",
    "    10. classical planning\n",
    "    11. planning and acting in the real world\n",
    "    12. knowledge representation\n",
    "    13. quantifying uncertainty\n",
    "    14. probabilistic reasoning\n",
    "    15. probabilistic reasoning over time\n",
    "    16. making simple decisions\n",
    "    17. making complex decisions\n",
    "    18. learning from examples\n",
    "    19. knowledge in learning\n",
    "    20. learning probabilistic models\n",
    "    21. natural language processing\n",
    "    22. reinforcement learning\n",
    "    23. natural language for communication\n",
    "    24. perception\n",
    "    25. robotics\n",
    "    26. mathematical background\n",
    "    27. notes on languages and algorithms\n",
    "- **understanding the artificial - on the furutre shape of artificial intelligence**\n",
    "    1. introduction: artificial intelligence: its future and its cultural roots\n",
    "    2. the cognitive dimension in the processing of natural language\n",
    "    3. making a mind versus modelling the brain: artificial intelligence back at the branchpoint\n",
    "    4. alternative intelligence\n",
    "    5. artificial intelligence as a dialectic of science and technology\n",
    "    6. biological and artificial intelligence\n",
    "    7. computers, musical notation and the externalization of knowledge: towards a comparative study in the hisory of information technology\n",
    "    8. cognitive science and the computer metaphor\n",
    "    9. intelligent behavior in machines\n",
    "    10. conclusions: the dissymmetry of mind and the role of the artificial \n",
    "    11. appendix: one hundred definitions of AI\n",
    "    12. Appendix B: an attempt at getting a basis for a rational definition of the artificial\n",
    "- **Computer and the brain** (von neumann)\n",
    "    1. The computer\n",
    "        - the analog procedure\n",
    "            - the conventional basic operations\n",
    "            - unusual basic operations\n",
    "        - the digital procedure\n",
    "            - markers, their combinations and embodiments\n",
    "            - digital machine types and their basic components\n",
    "            - parallel and serial schemes\n",
    "            - the conventional basic operations\n",
    "        - logical control\n",
    "            - plugged control\n",
    "            - logical tape control\n",
    "            - the principle of only one organ for each basic operation\n",
    "            - the consequent need for a special memory organ\n",
    "            - control by \"control sequence\" points\n",
    "            - memory-stored control\n",
    "            - modus operandi of the memory-stored control\n",
    "            - mixed forms of control\n",
    "        - mixed numerical procedures\n",
    "            - mixed representations of numbers. machines built on this basis\n",
    "        - precision\n",
    "            - reasons for the high (digital) precsion requirements\n",
    "        - characteristics of modern analog machines\n",
    "        - characteristics of modern digital machines\n",
    "            - active components; questions of speed\n",
    "            - number of active components required\n",
    "            - memory organs. access times and memory capacities\n",
    "            - memory registers built from active organs\n",
    "            - the hierarchic principle for memory organs\n",
    "            - memory components; question of access\n",
    "            - complexities on the concept of access time\n",
    "            - the principle of direct addressing\n",
    "    2. the brain\n",
    "        - simplified description of the function of the neuron\n",
    "        - the nature of the nerve impulse\n",
    "            - the process of stimulation\n",
    "            - the mechanism of stimulating pusles by pulses; its digital character\n",
    "            - time characteristics of nerve responses, fatigue and recovery\n",
    "            - size of a neuron. comparisons with artificial components\n",
    "            - energy dissipation\n",
    "        - stimulation criteria\n",
    "            - the simplest- elementary logical\n",
    "            - more complicated stimulation criteria\n",
    "            - the threshold\n",
    "            - the summation time\n",
    "            - stimulation criteria for receptors\n",
    "        - the problem of memory within the nervous system\n",
    "            - principles for estimating the capacity of the memory in the nervous system\n",
    "            - memory capacity estimated with these stipulations\n",
    "            - various possible physical embodiments of the memory\n",
    "            - analogies with artificial computing machines\n",
    "            - the underlying componentry of the memory need not be the same as that of the basic active organs\n",
    "        - digital and analog parts in the nervous system\n",
    "            - role of the genetic mechanism in the above context\n",
    "        - codes and their role in the contol of the functioning of a machine\n",
    "            - the concept of a complete code\n",
    "            - the concept of a short code\n",
    "            - the function of a short code\n",
    "        - the logical structure of the nervous system\n",
    "            - importance of the numerical procedures\n",
    "            - interaction of numerical procedures with logic\n",
    "            - reasons for expecting high precision requirements\n",
    "        - nature of the system of notations employed: not digital but statistical\n",
    "            - arithmetical deterioration. Roles of arithmetical and logical depths\n",
    "            - arithmetical precision or logical reliability, alternatives\n",
    "            - other statistical traits of the message systems that could be used\n",
    "        - the language of the brain not the language of mathematics\n",
    "- ** Handbook on Neural information processing**\n",
    "    1. Deep Learning of Representations (y bengio)\n",
    "        - a review and recent trends\n",
    "            - greedy layerwise pre-training\n",
    "            - undirected graphical models and boltzmann machines\n",
    "            - the restricted boltzmann machine\n",
    "            - the zoo: auto-encoders, sparse coding, predictive sparse decomposition, denoising auto-encoders, score matching and more\n",
    "        - convolutional architectures\n",
    "            - local receptive fields and weight sharing\n",
    "            - feature pooling\n",
    "        - learning invariant feature sets\n",
    "            - dealing with factors of variation: invariant features\n",
    "            - invariance via sparsity\n",
    "            - teasing apart explanatory factors via slow features analysis\n",
    "            - learning to pool features\n",
    "            - beyond learning invariant features\n",
    "        - disentangling factors of variation\n",
    "        - on the importance of top-down connections\n",
    "    2. Recurrent Neural networks\n",
    "        - architecture\n",
    "            - conncetionist network topologies\n",
    "            - specific architectures\n",
    "        - memory\n",
    "            - delayed activations as memory\n",
    "            - short-term memory and generic predictor\n",
    "            - types of memory kernels\n",
    "        - learning\n",
    "            - recurrent back-propagation: learning with fixedpoints\n",
    "            - back-propagation through time: learning with non-fixed points\n",
    "            - long-term dependencies\n",
    "        - modeling\n",
    "            - finite state automata\n",
    "            - beyond finite state automata\n",
    "            - applications\n",
    "                - natural language processing\n",
    "                - identification and control of dynamical systems\n",
    "    3. Supervised neural network models for processing graphs\n",
    "        - graphs\n",
    "        - neural models for graph processing\n",
    "            - the graph neural network model\n",
    "            - processing DAGs with recursive neural networks\n",
    "        - supervised learning for graph neural networks\n",
    "            - learning objective\n",
    "            - learning procedure for GNNs\n",
    "            - learning procedure for recursive neural networks\n",
    "    4. topics in cellular neural networks\n",
    "        - the CNN concept\n",
    "            - the architecture\n",
    "            - mathematical description\n",
    "            - other tasks CNN's can accomplish - the CNN universal machine\n",
    "        - a particular architecture\n",
    "            - the architecture and the equations\n",
    "            - the decoupling technique\n",
    "            - particular cases\n",
    "            - implementation issues\n",
    "            - a \"toy\" application: 1D \"edge\" detection\n",
    "        - two-grid coupled CNN's\n",
    "            - the architecture and the equations\n",
    "            - the decoupling technique\n",
    "            - boundary conditions (BC's) and their influence on pattern formation\n",
    "            - dispersion curve\n",
    "            - turing pattern formation mechanism\n",
    "            - boundary conditions in 2D CNN's\n",
    "    5. approximating multivariable functions by feedforward neural nets\n",
    "        - dictionaries and variable-basis approximation\n",
    "        - the universal approximation property\n",
    "        - quadratic rates of approximation\n",
    "        - geometric rates of approximation\n",
    "        - approximation of balls in variational norms\n",
    "        - best approximation and non-continuity of approximation\n",
    "        - tractability of approximation\n",
    "            - a shift in point-of-view: complexity and dimension\n",
    "            - measure worst-case error in approximation\n",
    "            - Gaussian RBF network tractability\n",
    "            - perceptron network tractability\n",
    "    6. Bochner integrals and neural networks\n",
    "        - variational norms and completeness\n",
    "        - bochner integrals\n",
    "        - spaces of bochner integrable functions\n",
    "        - main theorem\n",
    "        - an example involving the bessel potential\n",
    "        - application: a Gamma function inequality\n",
    "        - tensor-product interpretation\n",
    "        - pointwise-integrals vs. bochner integrals\n",
    "    7. semi-supervised learning\n",
    "        - self-training\n",
    "        - SSL with generative models\n",
    "        - Semi-supervised SVMs (S3VMs)\n",
    "        - semi-supervised learning with graphs\n",
    "        - semi-supervised learning with committees (SSLC)\n",
    "        - combination with active learning\n",
    "    8. Statistical relational learning\n",
    "        - relational learning versus attribute-value learning\n",
    "            - attribute-value learning\n",
    "            - relational learning\n",
    "            - mapping relational data to attribute-value data\n",
    "        - relational learning: tasks and formalisms\n",
    "            - inductive logic programming\n",
    "            - learning from graphs\n",
    "            - multi-relational data mining\n",
    "        - neural network based approaches to relational learning\n",
    "            - CIL$^2$P\n",
    "            - relational neural networks\n",
    "            - graph neural networks\n",
    "        - statistical relational learning\n",
    "            - structuring graphical models\n",
    "            - approaches in the relational database setting\n",
    "            - approaches in the logical setting\n",
    "        - general remarks and challenges\n",
    "            - understanding commonalities and differences\n",
    "            - parameter learning and structure learning\n",
    "            - scalability\n",
    "    9. Kernel methods for structured data\n",
    "        - mathematical foundations\n",
    "            - kernels\n",
    "            - supervised learning with kernels\n",
    "        - kernel machines for structured input\n",
    "            - SVM for binary classification\n",
    "            - SVM for refression\n",
    "            - smallest enclosing hypersphere\n",
    "            - kernel principal component analysis\n",
    "        - kernels on structured data\n",
    "            - basic kernels\n",
    "            - kernel combination\n",
    "            - kernels on discrete structures\n",
    "            - kernels from generative models\n",
    "            - kernels on logical representations\n",
    "        - learning kernels\n",
    "            - learning kernel combinations\n",
    "            - learning logical kernels\n",
    "        - supervised kernel machines for structured output\n",
    "    10. multiple classifier systems: theory, applications and tools\n",
    "        - MCS theory\n",
    "            - MCS architectures\n",
    "            - combining rules\n",
    "            - strategies for constructing a classifier ensemble\n",
    "        - applications\n",
    "            - remote-sensing data analysis\n",
    "            - document analysis\n",
    "            - biometrics\n",
    "            - figure and ground\n",
    "            - medical diagnosis support\n",
    "            - chemistry and biology\n",
    "            - time series Prediction/Analysis\n",
    "            - image and video analysis\n",
    "            - computer and network security\n",
    "    11. self organization and model learning: algorithms and applications\n",
    "        - snap-drift neural network\n",
    "        - snap-drift self-organizing map\n",
    "    12. Bayesian networks, introduction and practical applications\n",
    "    13. relevance feedback in content-based image retrieval: a survey\n",
    "        - content-based image retrieval \n",
    "            - low-level feature extraction\n",
    "            - similarity measure\n",
    "            - classification methods\n",
    "        - short-term learning RF\n",
    "        - long-term learning RF\n",
    "            - latent semantic indexing-based techniques\n",
    "            - correlation-based approaches\n",
    "            - clustering-based algorithms\n",
    "            - feature represtnation-based methods\n",
    "            - similarity measure modification-based approaches\n",
    "    14. learning structural representations of text documents in large document collections\n",
    "        - representation of unstructured or semi-structured text documents\n",
    "        - general framework for processing graph structured data\n",
    "        - self-organizing maps for structures\n",
    "        - graph neural networks\n",
    "        - clustering of the wikipedia data set\n",
    "    15. neural networks in bioinformatics\n",
    "        - analyzing DNA sequences\n",
    "        - peptide sequence analysis\n",
    "        - diagnostic predictions\n",
    "- **Neural Networks and COmputing: learning algorithms and applications**\n",
    "    1. introduction\n",
    "        - Neuron model\n",
    "        - historical remarks\n",
    "        - network architecture\n",
    "            - supervised neural networks\n",
    "                - McCulloh and Pitts model\n",
    "                - the perceptron model\n",
    "                - multi-layer feedforward network\n",
    "                - recurrent networks\n",
    "            - unsupervised neural networks\n",
    "        - modeling and learning mechanism\n",
    "            - determination of parameters\n",
    "            - gradient descent searching method\n",
    "    2. Learning performance and enhancement\n",
    "        - fundamentals of gradient descenet optimization\n",
    "        - conventional backpropagation algorithm\n",
    "        - convergence enhancement\n",
    "            - extended backpropagation algorithm\n",
    "            - least squares based training algorithm\n",
    "            - extended least squares based algorithm\n",
    "        - initialization consideration\n",
    "            - weight initialization algorithm I-III\n",
    "        - global learning algorithms\n",
    "            - simulated annealing algorithm\n",
    "            - Alopex algorithm\n",
    "            - reactive Tabu search\n",
    "            - the NOVEL algorithm\n",
    "            - the heuristic hybrid global learning algorithm\n",
    "        - concluding remarks\n",
    "            - fast learning algorithms\n",
    "            - weight initialization methods\n",
    "            - global learning algorithms\n",
    "    3. Generalization and performance enhancement\n",
    "        - Cost function and performance surface\n",
    "            - maximum likelihood estimation\n",
    "            - the least-square cost function\n",
    "        - Higher-order statistic generalization\n",
    "            - definitions and properties of higher-order statistics\n",
    "            - the higher-order cumulants based cost function\n",
    "            - property of the higher-order cumulant cost function\n",
    "            - learning and generalization performance\n",
    "                - EX 1: Henon Attractor\n",
    "                - EX 2: Sunspot time-series\n",
    "        - regularization for generalization enhancement\n",
    "            - adaptive regularization parameter selection (ARPS) methods\n",
    "                - stalling identification method\n",
    "                - $\\lambda$ selection schemes\n",
    "            - synthetic function mapping\n",
    "        - concluding remarks\n",
    "            - objective function selection\n",
    "            - regularization selection\n",
    "    4. basis function networks for classification\n",
    "        - Linear separation and perceptions\n",
    "        - basis function model for parametric smoothing\n",
    "        - radial basis function network\n",
    "            - RBF networks architecture\n",
    "            - universal approximation\n",
    "            - initialization and clustering\n",
    "            - learning algorithms\n",
    "                - linear weights optimization\n",
    "                - gradient descent optimization\n",
    "                - hybrid of least squares and penalized optimization\n",
    "            - regularization networks\n",
    "         - advanced radial basis function networks\n",
    "             - support vector machine\n",
    "             - wavelet network\n",
    "             - fuzzy RBF controllers\n",
    "             - probabilistic neural netwrosk\n",
    "    5. self-organizing maps\n",
    "        - learning algorithm\n",
    "        - growing SOMs\n",
    "            - cell splitting grid\n",
    "            - growing hierarchical self-organizing quadtree map\n",
    "        - probabilistic SOMs\n",
    "            - cellular probabilistic SOM\n",
    "            - probabilistic regularized SOM\n",
    "        - clustering of SOM\n",
    "        - Multi-layer SOM for tree-structured data\n",
    "            - SOM input representation\n",
    "            - MLSOM training\n",
    "            - MLSOM visualization and classification\n",
    "    6. Classification and feature selection\n",
    "        - support vector machines (SVM)\n",
    "        - cost function\n",
    "            - MSE and MCE cost functions\n",
    "            - hybrid MCE-MSE cost function\n",
    "            - implementing MCE-MSE\n",
    "        - feature selection\n",
    "            - information theory\n",
    "                - mutual information\n",
    "                - probability density function (PDF) estimation\n",
    "            - MI based forward feature selection\n",
    "    7. Engineering applications\n",
    "        - electrical load forecasting\n",
    "        - content-based image retrieval using SOM\n",
    "        - feature selection for cDNA microarray\n",
    "- **Cellular neural networks and visual computing: foundations and applications**\n",
    "    1. Introduction\n",
    "    2. Notation, definition, and mathematical foundation\n",
    "        - basic notation and definitions\n",
    "        - mathematical foundations\n",
    "    3. characteristics and analysis of simple CNN templates\n",
    "    4. Simulation of the CNN dynamics\n",
    "        - integration of the standard CNN differential equation\n",
    "        - image input\n",
    "        - software simulation\n",
    "        - digital hardware accelerators\n",
    "        - analog CNN implementations\n",
    "        - scaling the signals\n",
    "        - discrete-time CNN (DTCNN)\n",
    "    5. Binary CNN characterization via boolean functions\n",
    "    6. uncoupled CNNs: unified theory and applications\n",
    "        - the complete stability phenomena\n",
    "        - explcit CNN output formula\n",
    "        - proof of completely stable CNN theorem\n",
    "        - the primary CNN mosaic\n",
    "        - explicit formula for transient waveform and settling time\n",
    "        - which local boolean functions are realizable by uncoupled CNNs?\n",
    "        - geometrical interpretations\n",
    "        - how to design uncoupled CNNs with prescribed Boolean functions\n",
    "        - how to realize non-separable local boolean functions?\n",
    "    7. introduction to the CNN universal machine\n",
    "        - global clock and global wire\n",
    "        - set inclusion\n",
    "        - translation of sets and binary images\n",
    "        - opening and closing and implemnting any morphological operator\n",
    "        - implementing any prescribed boolean transition function by not more than 256 templates\n",
    "        - minimizing the number of templates when implementing any possible boolean transition function\n",
    "        - analog-to-digital array converter\n",
    "    8. Back to basics: nonlinear dynamics and complete stability\n",
    "        - a glimpse of things to come\n",
    "        - an oscillatory CNN with only two cells\n",
    "        - a chaotic CNN iwth only two cells and one sinusoidal input\n",
    "        - symmetrical **A** template implies complete stability\n",
    "        - positive and sign-symmetric **A** template implies complete stability\n",
    "        - positive and cell-linking **A** template implies complete stability\n",
    "        - stability of some sign-antisymmetric CNNs\n",
    "    9. The CNN universal machine (CNN-UM)\n",
    "        - the architecture\n",
    "        - a simple example in more detail\n",
    "        - a very simple exampleon the circuit level\n",
    "        - language compiler, operating system\n",
    "    10. Template design tools\n",
    "        - various design techniques\n",
    "        - binary representation, linear separability, and simple decomposition\n",
    "        - template optimization\n",
    "        - template decomposition techniques\n",
    "    11. CNNs for linear image processing\n",
    "        - linear image processing with **B** templates is equivalent to spatial convolution with FIR kernels\n",
    "        - spatial frequency characterization\n",
    "        - a primer on properties and applications of discrete-space Fourier transform (DSFT)\n",
    "        - linear image processing with **A** and **B** templates is equivalent to spatial convolution with IIR kernels\n",
    "    12. coupled CNN with linear synaptic weights\n",
    "        - active and inactive cells, dynamic local rules\n",
    "        - binary activation pattern and template format\n",
    "        - a simple propagating type example with B/W symmetrical rule\n",
    "        - the connectivity problem\n",
    "    13. uncoupled standard CNNs with nonlinear synaptic weights\n",
    "        - dynamic equations and DP plot\n",
    "    14. standard CNNs with delayed synaptic weights and motion analysis\n",
    "        - dynamic equations\n",
    "        - **motion analysis - discrete time and continuous time image acquisition**\n",
    "    15. video microprocessors - analog and digital VLSI implementation of the CNN universal machine\n",
    "        - the analog CNN core\n",
    "        - analogic CNN-UM cell\n",
    "        - emulated digital implementation\n",
    "        - the visual microprocesso and its computational infrastructure\n",
    "        - computing power comparison\n",
    "    16. CNN models in the visual pathway and the \"bionic eye\"\n",
    "        - receptive field organization, synaptic weights, and cloning template\n",
    "        - some protoype elementary functions and CNN models of the visual pathway\n",
    "        - **a simple qualitative \"engineering\" model of a vertebrate retina**\n",
    "        - the \"bionic eye\" implemented on a CNN universal machine\n",
    "- **An information-theoretic approach to neural computing**\n",
    "    1. Introduction\n",
    "    2. Preliminaries of Information theory and neural networks\n",
    "        - Elements of information theory\n",
    "            - entropy and information\n",
    "            - joint entropy and conditional entropy\n",
    "            - kullback-leibler entropy\n",
    "            - mutual information\n",
    "            - differential entropy, relative entropy, and mutual information\n",
    "            - chain rules\n",
    "            - fundamental information theory inequalities\n",
    "            - coding theory\n",
    "        - elements of the theory of neural networks\n",
    "            - neural network modeling\n",
    "            - neural architectures\n",
    "            - learning paradigms\n",
    "            - feedforward networks: backpropagation\n",
    "            - stochastic recurrent networks: boltzmann machine\n",
    "            - unsupervised competitive learning\n",
    "            - biological learning rules\n",
    "    3. I - Unsupervised Learning\n",
    "        1. Linear Feature Extraction: infomax principle\n",
    "            - principal component analysis: statistical approach\n",
    "                - PCA and diagonalization of the covariance matrix\n",
    "                - PCA and optimal reconstruction\n",
    "                - neural network algorithms and PCA\n",
    "            - information theoretic approach: infomax\n",
    "                - minimization of information loss principle and infomax principle\n",
    "                - upper bound of information loss\n",
    "                - information capacity as a Lyapanov function of the general stochastic approximation\n",
    "        2. independent component analysis: general formulation and linear case\n",
    "            - ICA-definition\n",
    "            - General criteria for ICA\n",
    "                - cumulant expansion based criterion for ICA\n",
    "                - mutual information as criterion for ICA\n",
    "            - linear ICA\n",
    "            - Gaussian input distribution and linear ICA\n",
    "                - networks with anti-symmetric lateral connections\n",
    "                - neworks with symmetrix lateral connections\n",
    "                - examples of learning with symmetric and anti-symmetric networks\n",
    "            - Learning in gaussian ICA with rotation matrices: PCA\n",
    "                - relationship between PCA and ICA in gaussian input case\n",
    "                - linear gaussian ICA and the output dimension reductions\n",
    "            - linear ICA in arbitrary input distribution\n",
    "                - some properties of cumulants at the output of a linear transformation\n",
    "                - the edgeworth expansion criteria and theorem 4.6.2\n",
    "                - algorithms for output factorization in the non-gaussian case\n",
    "                - experimental results of linear ICA algorithms in the non-gaussian case\n",
    "        3. Nonlinear feature extraction: boolean stochastic networks\n",
    "            - Infomax principle for boltzmann machines\n",
    "                - learning model\n",
    "                - examples of infomax principle in boltzmann machine\n",
    "            - redundancy minimization and infomax for the boltzmann machine\n",
    "                - learning model\n",
    "                - numerical complexity of the learning rule\n",
    "                - factorial learning experiments\n",
    "                - **receptive fields formation from a retina**\n",
    "        4. nonlinear feature extraction: deterministic neural networks\n",
    "            - redundancy reduction by triangular volume conserving architectures\n",
    "                - networks with linear, sigmoidal and higher order activation functions\n",
    "                - simulation and results\n",
    "            - unsupervised modeling of chaotic time series\n",
    "                - dynamical systems modeling\n",
    "            - redundancy reduction by general symplectic architectures\n",
    "                - general entropy preserving nonlinear maps\n",
    "                - optimizing a parameterized symplectic map\n",
    "                - density estimation and novelty\n",
    "            - example **theory of early vision**\n",
    "                - theoretical background\n",
    "                - retina model\n",
    "    4. II - Supervised learning\n",
    "        1. Supervised learning and statistical estimation\n",
    "            - statistical parameter estimation - basic definitions\n",
    "                - cramer-rao inequality for unbiased estimators\n",
    "            - maximum likelihood estimators\n",
    "                - maximum likelihood and the information measure\n",
    "            - maximum a posteriori estimations\n",
    "            - extentions of MLE to include model selection\n",
    "                - akaike's information theoretic criterion (AIC)\n",
    "                - minimal description length and stochastic complexity\n",
    "            - generalization and learning on the same data set\n",
    "        2. statistical physics theory of supervised learning and generalization\n",
    "            - statistical mechanics theory of supervised learning\n",
    "                - maximum entropy principle\n",
    "                - probability inference with an ensemble of networks\n",
    "                - information gain and complexity analysis\n",
    "            - learning with higher order neural networks\n",
    "                - partition function evaluation\n",
    "                - information gain in polynomail networks\n",
    "                - numerical experiments\n",
    "            - learning with general feedforward neural networks\n",
    "                - partition function approximation \n",
    "                - numerical experiments\n",
    "            - statistical theory of unsupervised and supervised factorial learning\n",
    "                - statistical theory of unsupervised factorial learning\n",
    "                - duality between unsupervised and maximum likelihood based supervised learning\n",
    "        3. composite networks\n",
    "            - cooperation and specialization in composite networks\n",
    "            - composite models as gaussian mixtures\n",
    "        4. information theory based regularizing methods\n",
    "            - theoretical framework\n",
    "                - network complexity regulation\n",
    "                - network architecture and learning paradigm\n",
    "                - applications of them mutual information based penalty term\n",
    "            - regularization in stochastic potts neural network\n",
    "- **Neural network design**\n",
    "    1. Inroduction\n",
    "        - objectives\n",
    "        - history\n",
    "        - biological inspiration\n",
    "    2. Neuron model and network architectures\n",
    "        - objectives\n",
    "        - theory and examples\n",
    "            - notation\n",
    "            - neuron model\n",
    "                - single-input neuron\n",
    "                - transfer functions\n",
    "                - multiple-input neuron\n",
    "            - network architectures\n",
    "                - a layer of neurons\n",
    "                - multiple layers of neurons\n",
    "                - recurrent networks\n",
    "    3. an illustrative example\n",
    "        - objectives\n",
    "        - theory and examples\n",
    "            - problem statement\n",
    "            - perceptron\n",
    "                - two-input case\n",
    "                - pattern recognition example\n",
    "            - hamming network\n",
    "                - feedforward layer\n",
    "                - recurrent layer\n",
    "            - hopfield network\n",
    "    4. perceptron learning rule\n",
    "        - objectives\n",
    "        - theory and examples\n",
    "            - learning rules\n",
    "            - perceptron architecture\n",
    "                - single-neuron perceptron\n",
    "                - multiple-neuron perceptron\n",
    "            - perceptron learning rule\n",
    "                - test problem\n",
    "                - constructing learning rules\n",
    "                - unified learning rule\n",
    "                - training multiple-neuron perceptrons\n",
    "            - proof of convergence\n",
    "    5. signal and weight vector spaces\n",
    "        - objectives\n",
    "        - theory and examples\n",
    "            - linear vector spaces\n",
    "            - linear independence\n",
    "            - spanning a space\n",
    "            - inner product\n",
    "            - norm\n",
    "            - orthogonality\n",
    "                - gram-schmidt orthogonalization\n",
    "            - vector expansions\n",
    "                - reciprocal basis vectors\n",
    "    6. linear transformations for neural networks\n",
    "        - objectives\n",
    "        - theory and examples\n",
    "            - linear transformations\n",
    "            - matrix representations\n",
    "            - change of basis\n",
    "            - eigenvalues and eigenvectors\n",
    "                - diagonalization\n",
    "    7. supervised hebbian learning\n",
    "        - objectives\n",
    "        - theory and examples\n",
    "            - linear associator\n",
    "            - the Hebb rule\n",
    "            - pseudoinverse rule\n",
    "            - application\n",
    "            - variations of Hebbian learning\n",
    "    8. performance surgaces and optimum points\n",
    "        - objectives\n",
    "        - theory and examples\n",
    "            - taylor series\n",
    "                - vector case\n",
    "            - directional derivatives\n",
    "            - minima\n",
    "            - necessary conditions for optimality\n",
    "                - first-order conditions\n",
    "                - second-order conditions\n",
    "            - quadratic functions\n",
    "                - eigensystem of the Hessian\n",
    "    9. performance optimization\n",
    "        - objectives\n",
    "        - theory and examples\n",
    "            - steepest descent\n",
    "                - stable learning rates\n",
    "                - minimizing along a line\n",
    "            - newton's method\n",
    "            - conjugate gradient\n",
    "    10. widrow-hoff learning\n",
    "        - objectives\n",
    "        - theory and examples\n",
    "            - ADALINE network\n",
    "            - mean square error\n",
    "            - LMS algorithm\n",
    "            - analysis of convergence\n",
    "            - adaptive filtering\n",
    "                - adaptive noise cancellation\n",
    "                - echo cancellation\n",
    "    11. backpropagation\n",
    "        - objectives\n",
    "        - theory and examples\n",
    "            - multilayer perceptrons\n",
    "                - pattern classification\n",
    "                - function approximation\n",
    "            - the backpropagation algorithm\n",
    "                - performance index\n",
    "                - chain rule\n",
    "                - backpropagating the sensitivities\n",
    "            - using backpropagation\n",
    "                - choice of network architecture\n",
    "                - convergence\n",
    "                - generalization\n",
    "    12. variations on backpropagation\n",
    "        - drawbacks of backpropagation\n",
    "            - performance surface example\n",
    "            - convergence example\n",
    "        - heuristic modifications of backpropagation\n",
    "            - momentum\n",
    "            - variable learning rate\n",
    "        - numerical optimization techniques\n",
    "            - conjugate gradient\n",
    "            - levenberg-marquardt algorithm\n",
    "    13. associative learning\n",
    "        - simple associative network\n",
    "        - unsupervised Hebb rule\n",
    "            - hebb rule with decay\n",
    "        - simple recognition network\n",
    "        - instar rule\n",
    "            - Kohonen rule\n",
    "        - simple recall network\n",
    "        - outstar rule\n",
    "    14. competitive networks\n",
    "        - Hamming network\n",
    "        - competitive layer\n",
    "            - competitive learning\n",
    "            - problems with competitive layers\n",
    "        - competitive layers in biogy\n",
    "        - self-organizing feature maps\n",
    "            - improving feature maps\n",
    "        - learning vector quantization\n",
    "            - LVQ learning\n",
    "            - improving LVQ networks (LVQ2)\n",
    "    15. grossberg network\n",
    "        - biological motivation: vision\n",
    "            - illusions\n",
    "            - vision normalization\n",
    "        - basic nonlinear model\n",
    "        - two-layer competitive network\n",
    "            - choice of transfer function\n",
    "            - learning law\n",
    "        - relation to kohonen law\n",
    "    16. adaptive resonance theory\n",
    "        - overview of adaptive resonance\n",
    "        - layer - steady state analysis\n",
    "        - orienting subsystem\n",
    "        - learning law: L1-L2\n",
    "            - subset/superset dilemma\n",
    "            - learning law\n",
    "        - ART1 Algorithm summary\n",
    "            - initialization \n",
    "            - algorithm\n",
    "    17. stability\n",
    "        - recurrent networks\n",
    "        - stability concepts\n",
    "        - lyapunov stability theorem\n",
    "        - pendulum example\n",
    "        - lasalles invariance theorem\n",
    "    18. Hopfield network\n",
    "        - hopfield model\n",
    "        - Lyapunov function\n",
    "            - invariant sets\n",
    "            - hopfield attractors\n",
    "        - effect of gain\n",
    "        - hopfield design\n",
    "            - content-addressable memory\n",
    "            - Hebb rule\n",
    "            - Lyapunov surface\n",
    "    19. Epilogue\n",
    "        - feedforward and related networks\n",
    "        - competitive networks\n",
    "        - dynamic associative memory networks\n",
    "        - classical foundations of neural networks\n",
    "- **Introduction to theory of computation**\n",
    "    1. introduction\n",
    "    2. the hopfield model\n",
    "        - the associative memory problem\n",
    "        - statistical mechanics of magnetic systems\n",
    "        - stochastic networks\n",
    "        - capacity of the stochastic network\n",
    "    3. extensions of the hopfield model\n",
    "        - variations on the hopfield model\n",
    "        - correlated patterns\n",
    "        - continuous-valued units\n",
    "        - hardware implementations\n",
    "        - temporal sequences of patterns\n",
    "    4. optimization problems\n",
    "        - the weighted matching problem\n",
    "        - the travelling salesman problem\n",
    "        - graph bipartitioning\n",
    "        - optimization problems in image processing\n",
    "    5. simple perceptrons\n",
    "        - feed-forward networks\n",
    "        - threshold units\n",
    "        - proof of convergence of the percepron learning rule\n",
    "        - linear units\n",
    "        - nonlinear units\n",
    "        - stochastic units\n",
    "        - capactity of the simple perceptron\n",
    "    6. multi-layer networks\n",
    "        - back-propagation\n",
    "        - variations on back-propagation\n",
    "        - performance of multi-layer feed-forward networks\n",
    "        - a theoretical framework for generalization\n",
    "        - optimal network architectures\n",
    "    7. recurrent networks\n",
    "        - boltzmann machines\n",
    "        - recurrent back-propagation\n",
    "        - learning time sequences\n",
    "        - reinforcement learning\n",
    "    8. unsupervised Hebbian learning\n",
    "        - unsupervised learning\n",
    "        - one linear unit \n",
    "        - principal component analysis\n",
    "        - self-organizing feature extraction\n",
    "    9. unsupervised competitive learning\n",
    "        - simple competitive learning\n",
    "        - adaptive resonance theory\n",
    "        - feature mapping\n",
    "        - theory of feature mapping\n",
    "        - the travelling salesman problem\n",
    "        - hybrid learning schemes\n",
    "    10. formal statistical mechanics of neural networks\n",
    "        - the hopfield model\n",
    "        - gardner theory of the connections\n",
    "    11. Statistical mechanics\n",
    "        - the boltzmann-gibbs distribution\n",
    "        - free energy and entropy\n",
    "        - stochastic dynamics\n",
    "- **Neural networks - a systematic introduction**\n",
    "     1. The biological paradigm (PDF)\n",
    "        - Neural computation\n",
    "            - Natural and artificial neural networks\n",
    "            - Models of computation\n",
    "            - Elements of a computing model\n",
    "        - Networks of neurons\n",
    "            - Structure of the neurons\n",
    "            - Transmission of information\n",
    "            - Information processing at the neurons and synapses\n",
    "            - Storage of information - Learning\n",
    "            - The neuron - a self-organizing system\n",
    "        - Artificial neural networks\n",
    "            - Networks of primitive functions\n",
    "            - Approximation of functions\n",
    "            - Caveat\n",
    "        - Historical and bibliographical remarks\n",
    "     2. Threshold logic (PDF)\n",
    "        - Networks of functions\n",
    "            - Feed-forward and recurrent networks\n",
    "            - The computing units\n",
    "        - Synthesis of Boolean functions\n",
    "            - Conjunction, disjunction, negation\n",
    "            - Geometric interpretation\n",
    "            - Constructive synthesis\n",
    "        - Equivalent networks\n",
    "            - Weighted and unweighted networks\n",
    "            - Absolute and relative inhibition\n",
    "            - Binary signals and pulse coding\n",
    "        - Recurrent networks\n",
    "            - Stored state networks\n",
    "            - Finite automata\n",
    "            - Finite automata and recurrent networks\n",
    "            - A first classification of neural networks\n",
    "        - Harmonic analysis of logical function\n",
    "            - General expression\n",
    "            - The Hadamard-Walsh transform\n",
    "            - Applications of threshold logic\n",
    "        - Historical and bibliographical remarks\n",
    "     3. Weighted Networks - The Perceptron (PDF)\n",
    "        - Perceptrons and parallel processing\n",
    "            - Perceptrons as weighted threshold elements\n",
    "            - Computational limits of the perceptron model\n",
    "        - Implementation of logical functions\n",
    "            - Geometric interpretation\n",
    "            - The XOR problem\n",
    "        - Linearly separable functions\n",
    "            - Linear separability\n",
    "            - Duality of input space and weight space\n",
    "            - The error function in weight space\n",
    "            - General decision curves\n",
    "        - Applications and biological analogy\n",
    "            - Edge detection with perceptrons\n",
    "            - The structure of the retina\n",
    "            - Pyramidal networks and the neocognitron\n",
    "            - The silicon retina\n",
    "        - Historical and bibliographical remarks\n",
    "     4. Perceptron learning(PDF)\n",
    "        - Learning algorithms for neural networks\n",
    "            - Classes of learning algorithms\n",
    "            - Vector notation\n",
    "            - Absolute linear separability\n",
    "            - The error surface and the search method\n",
    "        - Algorithmic learning\n",
    "            - Geometric visualization\n",
    "            - Convergence of the algorithm\n",
    "            - Accelerating convergence\n",
    "            - The pocket algorithm\n",
    "            - Complexity of perceptron learning\n",
    "        - Linear programming\n",
    "            - Inner points of polytopes\n",
    "            - Linear separability as linear optimization\n",
    "            - Karmarkars Algorithm\n",
    "        - Historical and bibliographical remarks\n",
    "     5. Unsupervised learning and clustering algorithms(PDF)\n",
    "        - Competitive learning\n",
    "            - Generalization of the perceptron problem\n",
    "            - Unsupervised learning through competition\n",
    "        - Convergence analysis\n",
    "            - The one-dimensional case - Energy function\n",
    "            - Multidimensional case - The classical methods\n",
    "            - Unsupervised learning as minimization problem\n",
    "            - Stability of the solutions\n",
    "        - Principal component analysis\n",
    "            - Unsupervised reinforcement learning\n",
    "            - Convergence of the learning algorithm\n",
    "            - Multiple principal components\n",
    "        - Examples\n",
    "            - Pattern recognition\n",
    "            - Image compression\n",
    "        - Historical and bibliographical remarks\n",
    "     6. One and two layered networks(PDF)\n",
    "        - Structure and geometric visualization\n",
    "            - Network architecture\n",
    "            - The XOR problem revisited\n",
    "            - Geometric visualization\n",
    "        - Counting regions in input and weight space\n",
    "            - Weight space regions for the XOR problem\n",
    "            - Bipolar vectors\n",
    "            - Projection of the solution regions\n",
    "            - Geometric interpretation\n",
    "        - Regions for two layered networks\n",
    "            - Regions in weight space for the XOR problem\n",
    "            - Number of regions in general\n",
    "            - Consequences\n",
    "            - The Vapnik-Chervonenkis dimension\n",
    "            - The problem of local minima\n",
    "        - Historical and bibliographical remarks\n",
    "     7. The backpropagation algorithm(PDF)\n",
    "        - Learning as gradient descent\n",
    "            - Differentiable activation functions\n",
    "            - Regions in input space\n",
    "            - Local minima of the error function\n",
    "        - General feed-forward networks\n",
    "            - The learning problem\n",
    "            - Derivatives of network functions\n",
    "            - Steps of the backpropagation algorithm\n",
    "            - Learning with Backpropagation\n",
    "        - The case of layered networks\n",
    "            - Extended network\n",
    "            - Steps of the algorithm\n",
    "            - Backpropagation in matrix form\n",
    "            - The locality of backpropagation\n",
    "            - An Example\n",
    "        - Recurrent networks\n",
    "            - Backpropagation through time\n",
    "            - Hidden Markov Models\n",
    "            - Variational problems\n",
    "        - Historical and bibliographical remarks\n",
    "     8. Fast learning algorithms(PDF)\n",
    "        - Introduction - Classical backpropagation\n",
    "            - Backpropagation with momentum\n",
    "            - The fractal geometry of backpropagation\n",
    "        - Some simple improvements to backpropagation\n",
    "            - Initial weight selection\n",
    "            - Clipped derivatives and offset term\n",
    "            - Reducing the number of floating-point operations\n",
    "            - Data decorrelation\n",
    "        - Adaptive step algorithms\n",
    "            - Silva and Almeidas algorithm\n",
    "            - Delta-bar-delta\n",
    "            - RPROP\n",
    "            - The Dynamic Adaption Algorithm\n",
    "        - Second-order algorithms\n",
    "            - Quickprop\n",
    "            - Second-order backpropagation\n",
    "        - Relaxation methods\n",
    "            - Weight and node perturbation\n",
    "            - Symmetric and asymmetric relaxation\n",
    "            - A final thought on taxonomy\n",
    "        - Historical and bibliographical remarks\n",
    "     9. Statistics and Neural Networks(PDF)\n",
    "        - Linear and nonlinear regression\n",
    "            - The problem of good generalization\n",
    "            - Linear regression\n",
    "            - Nonlinear units\n",
    "            - Computing the prediction error\n",
    "            - The jackknife and cross-validation\n",
    "            - Committees of networks\n",
    "        - Multiple regression\n",
    "            - Visualization of the solution regions\n",
    "            - Linear equations and the pseudoinverse\n",
    "            - The bidden layer\n",
    "            - Computation of the pseudoinverse\n",
    "        - Classification networks\n",
    "            - An application: NETtalk\n",
    "            - The Bayes property of classifier networks\n",
    "            - Connectionist speech recognition\n",
    "            - Autoregressive models for time series analysis\n",
    "        - Historical and bibliographical remarks\n",
    "     10. The complexity of learning(PDF)\n",
    "        - Network functions\n",
    "            - Learning algorithms for multilayer networks\n",
    "            - Hilberts problem and computability\n",
    "            - Kolmogorovs theorem\n",
    "        - Function approximation\n",
    "            - The one-dimensional case\n",
    "            - The multidimensional case\n",
    "        - Complexity of learning problems\n",
    "            - Complexity classes\n",
    "            - NP-complete learning problems\n",
    "            - Complexity of learning with AND-OR networks\n",
    "            - Simplifications of the network architecture\n",
    "            - Learning with hints\n",
    "        - Historical and bibliographical remarks\n",
    "     11. Fuzzy Logic(PDF)\n",
    "        - Fuzzy sets and fuzzy logic\n",
    "            - Imprecise data and imprecise rules\n",
    "            - The fuzzy set concept\n",
    "            - Geometric representation of fuzzy sets\n",
    "            - Set theory, logic operators and geometry\n",
    "            - Families of fuzzy operators\n",
    "        - Fuzzy inferences\n",
    "            - Inferences from imprecise data\n",
    "            - Fuzzy numbers and inverse operation\n",
    "        - Control with fuzzy logic\n",
    "            - Fuzzy controllers\n",
    "            - Fuzzy networks\n",
    "            - Function approximation with fuzzy methods\n",
    "            - The eye as a fuzzy system - color vision\n",
    "        - Historical and bibliographical remarks\n",
    "     12. Associative Networks(PDF)\n",
    "        - Associative pattern recognition\n",
    "            - Recurrent networks and types of associative memories\n",
    "            - Structure of an associative memory\n",
    "            - The eigenvector automaton\n",
    "        - Associative learning\n",
    "            - Hebbian Learning - The correlation matrix\n",
    "            - Geometric interpretation of Hebbian learning\n",
    "            - Networks as dynamical systems - Some experiments\n",
    "            - Another visualization\n",
    "        - The capacity problem\n",
    "        - The pseudoinverse\n",
    "            - Definition and properties of the pseudoinverse\n",
    "            - Orthogonal projections\n",
    "            - Holographic memories\n",
    "            - Translation invariant pattern recognition\n",
    "        - Historical and bibliographical remarks\n",
    "     13. The Hopfield Model(PDF)\n",
    "        - Synchronous and asynchronous networks\n",
    "            - Recursive networks with stochastic dynamics\n",
    "            - The bidirectional associative memory\n",
    "            - The energy function\n",
    "        - Definition of Hopfield networks\n",
    "            - Asynchronous networks\n",
    "            - Examples of the model\n",
    "            - Isomorphism between the Hopfield and Ising models\n",
    "        - Converge to stable states\n",
    "            - Dynamics of Hopfield networks\n",
    "            - Convergence proof\n",
    "            - Hebbian learning\n",
    "        - Equivalence of Hopfield and perceptron learning\n",
    "            - Perceptron learning in Hopfield networks\n",
    "            - Complexity of learning in Hopfield models\n",
    "        - Parallel combinatorics\n",
    "            - NP-complete problems and massive parallelism\n",
    "            - The multiflop problem\n",
    "            - The eight rooks problem\n",
    "            - The eight queens problem\n",
    "            - The traveling salesman\n",
    "            - The limits of Hopfield networks\n",
    "        - Implementation of Hopfield networks\n",
    "            - Electrical implementation\n",
    "            - Optical implementation\n",
    "        - Historical and bibliographical remarks\n",
    "     14. Stochastic networks(PDF)\n",
    "        - Variations of the Hopfield model\n",
    "            - The continuous model\n",
    "        - Stochastic systems\n",
    "            - Simulated annealing\n",
    "            - Stochastic neural networks\n",
    "            - Markov chains\n",
    "            - The Boltzmann distribution\n",
    "            - Physical meaning of the Boltzmann distribution\n",
    "        - Learning algorithms and applications\n",
    "            - Boltzmann learning\n",
    "            - Combinatorial optimization\n",
    "        - Historical and bibliographical remarks\n",
    "     15. Kohonen networks(PDF)\n",
    "        - Self-organization\n",
    "            - Charting input space\n",
    "            - Topology preserving maps in the brain\n",
    "        - Kohonens model\n",
    "            - Learning algorithm\n",
    "            - Mapping low dimensional spaces with high-dimensional grids\n",
    "        - Analysis of convergence\n",
    "            - Potential function - the one-dimensional case\n",
    "            - The two-dimensional case\n",
    "            - Effect of a units neighborhood\n",
    "            - Metastable states\n",
    "            - What dimension for Kohonen networks?\n",
    "        - Applications\n",
    "            - Approximation of functions\n",
    "            - Inverse kinematics\n",
    "        - Historical and bibliographical remarks\n",
    "     16. Modular Neural Network(PDF)\n",
    "        - Constructive algorithms for modular networks\n",
    "            - Cascade correlation\n",
    "            - Optimal modules and mixtures of experts\n",
    "        - Hybrid networks\n",
    "            - The ART architecures\n",
    "            - Maximum entropy\n",
    "            - Counterpropagation networks\n",
    "            - Spline networks\n",
    "            - Radial basis functions\n",
    "        - Historical and bibliographical remarks\n",
    "     17. Genetic Algorithms(PDF)\n",
    "        - Coding and operators\n",
    "            - Optimization problems\n",
    "            - Methods of stochastic optimization\n",
    "            - Genetic coding\n",
    "            - Information exchange with genetic operators\n",
    "        - Properties of genetic algorithms\n",
    "            - Convergence analysis\n",
    "            - Deceptive problems\n",
    "            - Genetic drift\n",
    "            - Gradient methods versus genetic algorithms\n",
    "        - Neural networks and genetic algorithms\n",
    "            - The problem of symmetries\n",
    "            - A numerical experiment\n",
    "            - Other applications of Gas\n",
    "        - Historical and bibliographical remarks\n",
    "     18. Hardware for neural networks(PDF)\n",
    "        - Taxonomy of neural hardware\n",
    "            - Performance requirements\n",
    "            - Types of neurocomputers\n",
    "        - Analog neural networks\n",
    "            - Coding\n",
    "            - VLSI transistor circuits\n",
    "            - Transistors with stored charge\n",
    "            - CCD components\n",
    "        - Digital networks\n",
    "            - Numerical representation of weights and signals\n",
    "            - Vector and signal processors\n",
    "            - Systolic arrays\n",
    "            - One-dimensional structures\n",
    "        - Innovative computer architectures\n",
    "            - VLSI microprocessors for neural networks\n",
    "            - Optical computers\n",
    "            - Pulse coded networks\n",
    "        - Historical and bibliographical remarks\n",
    "- **Handbook of Neural Network Signal Processing**\n",
    "    1. Introduction to neural networks for signal processing\n",
    "    2. signal processing using the multilayer perceptron\n",
    "    3. Radial basis functions\n",
    "    4. an introduction to kernel-based learning algorithms\n",
    "    5. committee machines\n",
    "    6. dunamical neural networks and optimal signal processing\n",
    "    7. blind signal separation and blind deconvolution\n",
    "    8. neural networks and principal component analysis\n",
    "    9. applications of artificial neural networks to time series prediction\n",
    "    10. applications of ANNs to speech processing\n",
    "    11. learning and adaptive characterization of visual contents in image retrievel systems\n",
    "    12. applications of neural networks to image processing\n",
    "    13. hierarchical fuzzy neural networks for pattern classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
